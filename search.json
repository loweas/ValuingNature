[
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Contingent Valuation",
    "section": "",
    "text": "The contingent valuation method involves directly asking people, in a survey, how much they would be willing to pay for specific environmental services.  In some cases, people are asked for the amount of compensation they would be willing to accept to give up specific environmental services.  It is called contingent valuation, because people are asked to state their willingness to pay, contingent on a specific hypothetical scenario and description of the environmental service. This page will go through an adapted version based on James Fogarty and Hideo Aizaki\n\n\nOpen R. You will need additional packages DCchoice, Ecdat (Croissant and Graves 2020) and lmtest (Zeileis and Hothorn 2002).\n\n#install.packages(\"DCchoice\",repos = c(\"http://www.bioconductor.org/packages/release/bioc\",\"https://cran.rstudio.com/\"), dep = TRUE)\n\n#install.packages(ggplot2)\n#install.packages(dplyr)\n\nAfter installing the necessary packages, the next step is to load DCchoice, Ecdat, and lmtest into your current R session. The DCchoice package provides the core functions used in our analysis. Additionally, lmtest offers essential tools for model testing. The Ecdat package includes publicly available real-world datasets.\nFor this example, we’ll use the NaturalParks dataset to demonstrate how contingent valuation (CV) study data can be analyzed.\n\nlibrary(DCchoice)\nlibrary(Ecdat)\nlibrary(lmtest)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\n\nWe will use a built-in sample dataset from the Ecdat package. After loading the dataset, you can use the head() function to preview its contents. By default, head() displays the first six rows along with the column names, but you can adjust the number of rows shown by using the n argument. This function is a quick way to get an overview of the dataset’s structure.\n\n# Load the data from Ecdat package\ndata(NaturalPark, package = \"Ecdat\") \n\n# Display the first three rows of data          \nhead(NaturalPark, n = 5)                     \n\n  bid1 bidh bidl answers age    sex income\n1    6   18    3      yy   1 female      2\n2   48  120   24      yn   2   male      1\n3   48  120   24      yn   2 female      3\n4   24   48   12      nn   5 female      1\n5   24   48   12      ny   6 female      2\n\n\n\n\n\nThe NaturalParks (NP) dataset contains seven variables, each representing a specific aspect of the survey responses:\n\nbid1: The initial bid amount (in euros) presented in the first willingness-to-pay (WTP) question. In this dataset, there are four possible bid amounts: 6, 12, 24, and 48.\nbidh: The higher follow-up bid amount, shown only if the respondent answered “yes” to the initial WTP question.\nbidl: The lower follow-up bid amount, shown only if the respondent answered “no” to the initial WTP question.\nanswers: A factor variable representing the respondent’s answers to the two WTP questions. The four possible combinations are:\n\nnn: no to both\nny: no to first, yes to second\nyn: yes to first, no to second\nyy: yes to both\n\nSince there are four combinations, this factor variable has four levels.\n\nage: Age is grouped into six brackets rather than exact values. Higher bracket numbers correspond to older respondents.\nsex: A factor variable with two levels: “male” and “female.”\nincome: Income is also grouped into eight brackets. As with age, higher numbers represent higher income levels.\n\n\n\n\nThe decision identifies what each individual prefers. This is indicated by the “yes” and “no.” The variable needs to be converted into a numerical representation. To do this you will need to write a loop and create a binary indicator for when the individuals says yes to the first bid. This is indicated by the first letter of the variable starting with “y”\n\nNaturalPark$ans1 &lt;- ifelse(NaturalPark$answers == \"yy\" | NaturalPark$answers == \"yn\", 1, 0)\n\n# Display the first three rows of data          \nhead(NaturalPark, n = 5)   \n\n  bid1 bidh bidl answers age    sex income ans1\n1    6   18    3      yy   1 female      2    1\n2   48  120   24      yn   2   male      1    1\n3   48  120   24      yn   2 female      3    1\n4   24   48   12      nn   5 female      1    0\n5   24   48   12      ny   6 female      2    0\n\n\nNow we want to count the number of individuals who said yes for each price. This table shows the rows as yes or no for first bid and all the prices.\n\ntable(NaturalPark$ans1, NaturalPark$bid1) \n\n   \n     6 12 24 48\n  0 26 34 40 41\n  1 50 43 42 36\n\n\nThe table can be interpreted as follows:\n\nFor a bid price of €6, there are 76 survey responses. Out of these, 50 respondents said they would be willing to pay €6, while 26 said they would not.\nAnd so on for higher bid amounts.\n\nAs the bid price increases, we expect rationally (from law of demand) there will be a decline in the proportion of “yes” responses, since fewer people are likely to be willing to pay higher amounts for the same environmental improvement.\n\nThis pattern is visible in the table, particularly when reading across the row representing “yes” responses (often coded as 1), where the number of affirmative answers drops from 50 to 36, and continues decreasing with higher bids. Lets look at this in a graph.\n\n\n\nTo create our demand line, we will first have to convert the data in the right shape form.\n\nyes_data &lt;- as.data.frame(table(NaturalPark$ans1, NaturalPark$bid1)) %&gt;%\n  rename(Answer = Var1, Bid = Var2, Count = Freq) %&gt;%\n  filter(Answer == 1) %&gt;%\n  mutate(Bid = as.numeric(as.character(Bid)))\n\n# Display the first three rows of data          \nhead(yes_data, n = 5)  \n\n  Answer Bid Count\n1      1   6    50\n2      1  12    43\n3      1  24    42\n4      1  48    36\n\n\nNow we will use ggplot and visually show how people respond to bid prices:\n\nggplot(yes_data, aes(x = Count, y = Bid)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  geom_point(color = \"darkgreen\", size = 3) +\n  scale_y_continuous(breaks = yes_data$Bid) +\n  labs(\n    title = \"Decline in 'Yes' Responses with Higher Bid Prices\",\n    x = \"Number of 'Yes' Responses\",\n    y = \"Bid Amount (€)\"\n  ) +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nAnd voilà! There we have a downward sloping demand curve!\nPeople respond to prices which makes sense and suggest that people are responding in a way that they do in reality.\n\n\n\nNow that we have explored the data and tested peoples rational. We are going to estimate the willingness to pay for the contingent valuation question.\nFor now, we’ll ignore gender, income, and age. The model assumes that a person’s response :\n\n0 (“no, not willing to pay”)\n1 (“yes, willing to pay”) depends only on the bid amount (or “price”).\n\nSo this model includes just one explanatory variable which is the bid.\nUsing DCchoice the formula for this type of model is as follows:\nmodel1 &lt;- sbchoice(dep var ~ exp var | bid, dist = \"\", data = my.data)\nHere’s what each part means:\n\nmodel1: The name we give to save the model results (for example, sb1 for the first model).\n&lt;-: The assignment symbol that stores the model in model1.\nsbchoice: The function that runs the model.\ndep_var: The dependent variable (the responses coded as 0 = no, 1 = yes). For our first model this is ans1.\nexp_var: The explanatory variables other than the bid amount. Since we don’t have any for the first model, we just use 1 for the intercept.\n| bid: This part specifies the bid amount variable, which is bid1 in our example.\ndist = \"\": Specifies the distribution used; we’ll always use logistic, so it will be dist = \"logistic\"\ndata = my.data: The data frame that contains the data which in our case is NaturalPark.\n\nAfter fitting the model, we usually check the results with the summary() function. To focus on the coefficient estimates, we can use coeftest() from the lmtest package.\n\n# A very simple model\nsb1 &lt;- sbchoice(ans1 ~ 1 | bid1,  dist = \"logistic\", data = NaturalPark)\ncoeftest(sb1)\n\n\nz test of coefficients:\n\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.5500450  0.1998739  2.7520 0.005924 **\nBID         -0.0157223  0.0071807 -2.1895 0.028560 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe most important thing to notice in the model’s coefficients is the negative sign on the bid variable. No matter how the original data is coded, the bid will always show up as BID in the results. This negative sign means that as the bid price goes up, fewer people say “yes” they are less willing to pay that amount!\nThe results also show that this relationship is statistically significant, meaning it’s unlikely to be due to chance.\nLets see these results visually by using the plot() function. This plot shows the willingness-to-pay data along with a horizontal line marking the point where 50% of people say “yes.” From the plot, you can see that this 50% support happens at about €35.\n\n# plots the predicted support at each bid value \nplot(sb1, las = 1)  \n\n# adds a horizontal line to the plot \nabline(h = 0.5, lty = 2, col = \"red\") \n\n\n\n\n\n\n\n\n\n\n\nWe now look at the full model summary output we get when we use the sbchoice() function:\n\n#  Model summary\nsummary(sb1) \n\n\nCall:\nsbchoice(formula = ans1 ~ 1 | bid1, data = NaturalPark, dist = \"logistic\")\n\nFormula:\nans1 ~ 1 | bid1\n\nCoefficients: \n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.550045   0.199874   2.752  0.00592 **\nBID         -0.015722   0.007181  -2.190  0.02856 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nDistribution: logistic \nNumber of Obs.: 312  \nlog-likelihood: -212.3968 \npseudo-R^2: 0.0113 , adjusted pseudo-R^2: 0.0020 \nLR statistic: 4.841 on 1 DF, p-value: 0.028 \nAIC: 428.793653 , BIC: 436.279659 \n\nIterations: 4  \nConvergence: TRUE \n\nWTP estimates:\n Mean : 63.95526 \n Mean : 26.04338 (truncated at the maximum bid)\n Mean : 47.26755 (truncated at the maximum bid with adjustment)\n Median : 34.98512 \n\n\nThe summary output has several parts:\n\nThe model we estimated:\nFormula:\nans1 ~ 1 | bid1\n\nCoefficients: \n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.550045   0.199874   2.752  0.00592 **\nBID         -0.015722   0.007181  -2.190  0.02856 * \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nThe second part shows the model’s coefficients and whether they are statistically significant.\nDistribution: logistic \nNumber of Obs.: 312  \nlog-likelihood: -212.3968 \npseudo-R^2: 0.0113 , adjusted pseudo-R^2: 0.0020 \nLR statistic: 4.841 on 1 DF, p-value: 0.028 \nAIC: 428.793653 , BIC: 436.279659 \nThe third part shows how well the model fits the data. This helps us compare different models. It’s important to see “Convergence: TRUE,” which means the model worked properly. If not, you’ll get an error.\nIterations: 4  \nConvergence: TRUE \nThe fourth part shows the estimated average and median willingness to pay (WTP). Lets take a moment here\nWTP estimates:\n Mean : 63.95526 \n Mean : 26.04338 (truncated at the maximum bid)\n Mean : 47.26755 (truncated at the maximum bid with adjustment)\n Median : 34.98512 \n\n\n\nValue: Value: 63.95\nThis estimate can be calculated by taking the coefficient of the estimation on bid:\n\\(1/\\beta_{bid} = 1/-0.015722=63.95\\)\nThis is the unbounded mean and its calculated using the full range of the estimated distribution of WTP, even beyond your maximum bid.\nHow it’s calculated:\n\nUses the model’s estimated coefficients to integrate the WTP distribution from 0 to infinity (or theoretically negative infinity to positive infinity depending on the model).\nIssue: May overestimate WTP, especially if the upper tail is long (which it often is).\n\n\nmedianWTP=1/sb1$coefficients[2]\nmedianWTP\n\n     BID \n-63.6041 \n\n\n\n\n\nValue: 26.04\n\nThis is the mean WTP truncated at the maximum bid in your data.\n\\(1/\\beta_{bid}(1+exp(\\beta_0+\\sum(\\beta_nZ_n)))\\)\nHow it’s calculated:\n\nIntegration is limited from 0 up to the highest bid amount offered in your survey.\nWhy: This avoids overestimating WTP from extrapolating too far beyond your data.\n\n\nmedianWTP * (log(1 + exp(sb1$coefficients[1] + sb1$coefficients[2] * max(NaturalPark$bid1))) - log(1 + exp(sb1$coefficients[1])))\n\n     BID \n26.04338 \n\n\n\n\n\n#Value: 47.27\n\nThis is the same as #2 but with a correction applied to adjust for truncation bias.\nHow it’s calculated:\n\nStill truncated at the max bid, but includes a bias-correction factor based on the distribution. the truncated mean WTP with the adjustment of Boyle et~al.(1988)\nWhy: Balances realism (truncation) with statistical accuracy (adjustment).\n\n\n\n\nValue: 34.99\n\nThis is the bid level at which 50% of respondents are predicted to say “yes”.\nHow it’s calculated:\n\\(-(\\alpha/\\beta_{bid})\\)\n\nIt’s the bid where the predicted probability of saying “yes” is 0.5, based on your model.\nWhy: Commonly used because it’s less sensitive to skewed data than the mean.\n\n\n-sb1$coefficients[1]/sb1$coefficients[2]\n\n(Intercept) \n   34.98512"
  },
  {
    "objectID": "cv.html#packages",
    "href": "cv.html#packages",
    "title": "Contingent Valuation",
    "section": "",
    "text": "Open R. You will need additional packages DCchoice, Ecdat (Croissant and Graves 2020) and lmtest (Zeileis and Hothorn 2002).\n\n#install.packages(\"DCchoice\",repos = c(\"http://www.bioconductor.org/packages/release/bioc\",\"https://cran.rstudio.com/\"), dep = TRUE)\n\n#install.packages(ggplot2)\n#install.packages(dplyr)\n\nAfter installing the necessary packages, the next step is to load DCchoice, Ecdat, and lmtest into your current R session. The DCchoice package provides the core functions used in our analysis. Additionally, lmtest offers essential tools for model testing. The Ecdat package includes publicly available real-world datasets.\nFor this example, we’ll use the NaturalParks dataset to demonstrate how contingent valuation (CV) study data can be analyzed.\n\nlibrary(DCchoice)\nlibrary(Ecdat)\nlibrary(lmtest)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "cv.html#load-data",
    "href": "cv.html#load-data",
    "title": "Contingent Valuation",
    "section": "",
    "text": "We will use a built-in sample dataset from the Ecdat package. After loading the dataset, you can use the head() function to preview its contents. By default, head() displays the first six rows along with the column names, but you can adjust the number of rows shown by using the n argument. This function is a quick way to get an overview of the dataset’s structure.\n\n# Load the data from Ecdat package\ndata(NaturalPark, package = \"Ecdat\") \n\n# Display the first three rows of data          \nhead(NaturalPark, n = 5)                     \n\n  bid1 bidh bidl answers age    sex income\n1    6   18    3      yy   1 female      2\n2   48  120   24      yn   2   male      1\n3   48  120   24      yn   2 female      3\n4   24   48   12      nn   5 female      1\n5   24   48   12      ny   6 female      2"
  },
  {
    "objectID": "cv.html#data-variables",
    "href": "cv.html#data-variables",
    "title": "Contingent Valuation",
    "section": "",
    "text": "The NaturalParks (NP) dataset contains seven variables, each representing a specific aspect of the survey responses:\n\nbid1: The initial bid amount (in euros) presented in the first willingness-to-pay (WTP) question. In this dataset, there are four possible bid amounts: 6, 12, 24, and 48.\nbidh: The higher follow-up bid amount, shown only if the respondent answered “yes” to the initial WTP question.\nbidl: The lower follow-up bid amount, shown only if the respondent answered “no” to the initial WTP question.\nanswers: A factor variable representing the respondent’s answers to the two WTP questions. The four possible combinations are:\n\nnn: no to both\nny: no to first, yes to second\nyn: yes to first, no to second\nyy: yes to both\n\nSince there are four combinations, this factor variable has four levels.\n\nage: Age is grouped into six brackets rather than exact values. Higher bracket numbers correspond to older respondents.\nsex: A factor variable with two levels: “male” and “female.”\nincome: Income is also grouped into eight brackets. As with age, higher numbers represent higher income levels."
  },
  {
    "objectID": "cv.html#data-manipulation",
    "href": "cv.html#data-manipulation",
    "title": "Contingent Valuation",
    "section": "",
    "text": "The decision identifies what each individual prefers. This is indicated by the “yes” and “no.” The variable needs to be converted into a numerical representation. To do this you will need to write a loop and create a binary indicator for when the individuals says yes to the first bid. This is indicated by the first letter of the variable starting with “y”\n\nNaturalPark$ans1 &lt;- ifelse(NaturalPark$answers == \"yy\" | NaturalPark$answers == \"yn\", 1, 0)\n\n# Display the first three rows of data          \nhead(NaturalPark, n = 5)   \n\n  bid1 bidh bidl answers age    sex income ans1\n1    6   18    3      yy   1 female      2    1\n2   48  120   24      yn   2   male      1    1\n3   48  120   24      yn   2 female      3    1\n4   24   48   12      nn   5 female      1    0\n5   24   48   12      ny   6 female      2    0\n\n\nNow we want to count the number of individuals who said yes for each price. This table shows the rows as yes or no for first bid and all the prices.\n\ntable(NaturalPark$ans1, NaturalPark$bid1) \n\n   \n     6 12 24 48\n  0 26 34 40 41\n  1 50 43 42 36\n\n\nThe table can be interpreted as follows:\n\nFor a bid price of €6, there are 76 survey responses. Out of these, 50 respondents said they would be willing to pay €6, while 26 said they would not.\nAnd so on for higher bid amounts.\n\nAs the bid price increases, we expect rationally (from law of demand) there will be a decline in the proportion of “yes” responses, since fewer people are likely to be willing to pay higher amounts for the same environmental improvement.\n\nThis pattern is visible in the table, particularly when reading across the row representing “yes” responses (often coded as 1), where the number of affirmative answers drops from 50 to 36, and continues decreasing with higher bids. Lets look at this in a graph."
  },
  {
    "objectID": "cv.html#data-visualization",
    "href": "cv.html#data-visualization",
    "title": "Contingent Valuation",
    "section": "",
    "text": "To create our demand line, we will first have to convert the data in the right shape form.\n\nyes_data &lt;- as.data.frame(table(NaturalPark$ans1, NaturalPark$bid1)) %&gt;%\n  rename(Answer = Var1, Bid = Var2, Count = Freq) %&gt;%\n  filter(Answer == 1) %&gt;%\n  mutate(Bid = as.numeric(as.character(Bid)))\n\n# Display the first three rows of data          \nhead(yes_data, n = 5)  \n\n  Answer Bid Count\n1      1   6    50\n2      1  12    43\n3      1  24    42\n4      1  48    36\n\n\nNow we will use ggplot and visually show how people respond to bid prices:\n\nggplot(yes_data, aes(x = Count, y = Bid)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  geom_point(color = \"darkgreen\", size = 3) +\n  scale_y_continuous(breaks = yes_data$Bid) +\n  labs(\n    title = \"Decline in 'Yes' Responses with Higher Bid Prices\",\n    x = \"Number of 'Yes' Responses\",\n    y = \"Bid Amount (€)\"\n  ) +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nAnd voilà! There we have a downward sloping demand curve!\nPeople respond to prices which makes sense and suggest that people are responding in a way that they do in reality."
  },
  {
    "objectID": "cv.html#model-estimation",
    "href": "cv.html#model-estimation",
    "title": "Contingent Valuation",
    "section": "",
    "text": "Now that we have explored the data and tested peoples rational. We are going to estimate the willingness to pay for the contingent valuation question.\nFor now, we’ll ignore gender, income, and age. The model assumes that a person’s response :\n\n0 (“no, not willing to pay”)\n1 (“yes, willing to pay”) depends only on the bid amount (or “price”).\n\nSo this model includes just one explanatory variable which is the bid.\nUsing DCchoice the formula for this type of model is as follows:\nmodel1 &lt;- sbchoice(dep var ~ exp var | bid, dist = \"\", data = my.data)\nHere’s what each part means:\n\nmodel1: The name we give to save the model results (for example, sb1 for the first model).\n&lt;-: The assignment symbol that stores the model in model1.\nsbchoice: The function that runs the model.\ndep_var: The dependent variable (the responses coded as 0 = no, 1 = yes). For our first model this is ans1.\nexp_var: The explanatory variables other than the bid amount. Since we don’t have any for the first model, we just use 1 for the intercept.\n| bid: This part specifies the bid amount variable, which is bid1 in our example.\ndist = \"\": Specifies the distribution used; we’ll always use logistic, so it will be dist = \"logistic\"\ndata = my.data: The data frame that contains the data which in our case is NaturalPark.\n\nAfter fitting the model, we usually check the results with the summary() function. To focus on the coefficient estimates, we can use coeftest() from the lmtest package.\n\n# A very simple model\nsb1 &lt;- sbchoice(ans1 ~ 1 | bid1,  dist = \"logistic\", data = NaturalPark)\ncoeftest(sb1)\n\n\nz test of coefficients:\n\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.5500450  0.1998739  2.7520 0.005924 **\nBID         -0.0157223  0.0071807 -2.1895 0.028560 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe most important thing to notice in the model’s coefficients is the negative sign on the bid variable. No matter how the original data is coded, the bid will always show up as BID in the results. This negative sign means that as the bid price goes up, fewer people say “yes” they are less willing to pay that amount!\nThe results also show that this relationship is statistically significant, meaning it’s unlikely to be due to chance.\nLets see these results visually by using the plot() function. This plot shows the willingness-to-pay data along with a horizontal line marking the point where 50% of people say “yes.” From the plot, you can see that this 50% support happens at about €35.\n\n# plots the predicted support at each bid value \nplot(sb1, las = 1)  \n\n# adds a horizontal line to the plot \nabline(h = 0.5, lty = 2, col = \"red\")"
  },
  {
    "objectID": "cv.html#full-estimation",
    "href": "cv.html#full-estimation",
    "title": "Contingent Valuation",
    "section": "",
    "text": "We now look at the full model summary output we get when we use the sbchoice() function:\n\n#  Model summary\nsummary(sb1) \n\n\nCall:\nsbchoice(formula = ans1 ~ 1 | bid1, data = NaturalPark, dist = \"logistic\")\n\nFormula:\nans1 ~ 1 | bid1\n\nCoefficients: \n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.550045   0.199874   2.752  0.00592 **\nBID         -0.015722   0.007181  -2.190  0.02856 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nDistribution: logistic \nNumber of Obs.: 312  \nlog-likelihood: -212.3968 \npseudo-R^2: 0.0113 , adjusted pseudo-R^2: 0.0020 \nLR statistic: 4.841 on 1 DF, p-value: 0.028 \nAIC: 428.793653 , BIC: 436.279659 \n\nIterations: 4  \nConvergence: TRUE \n\nWTP estimates:\n Mean : 63.95526 \n Mean : 26.04338 (truncated at the maximum bid)\n Mean : 47.26755 (truncated at the maximum bid with adjustment)\n Median : 34.98512 \n\n\nThe summary output has several parts:\n\nThe model we estimated:\nFormula:\nans1 ~ 1 | bid1\n\nCoefficients: \n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.550045   0.199874   2.752  0.00592 **\nBID         -0.015722   0.007181  -2.190  0.02856 * \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nThe second part shows the model’s coefficients and whether they are statistically significant.\nDistribution: logistic \nNumber of Obs.: 312  \nlog-likelihood: -212.3968 \npseudo-R^2: 0.0113 , adjusted pseudo-R^2: 0.0020 \nLR statistic: 4.841 on 1 DF, p-value: 0.028 \nAIC: 428.793653 , BIC: 436.279659 \nThe third part shows how well the model fits the data. This helps us compare different models. It’s important to see “Convergence: TRUE,” which means the model worked properly. If not, you’ll get an error.\nIterations: 4  \nConvergence: TRUE \nThe fourth part shows the estimated average and median willingness to pay (WTP). Lets take a moment here\nWTP estimates:\n Mean : 63.95526 \n Mean : 26.04338 (truncated at the maximum bid)\n Mean : 47.26755 (truncated at the maximum bid with adjustment)\n Median : 34.98512 \n\n\n\nValue: Value: 63.95\nThis estimate can be calculated by taking the coefficient of the estimation on bid:\n\\(1/\\beta_{bid} = 1/-0.015722=63.95\\)\nThis is the unbounded mean and its calculated using the full range of the estimated distribution of WTP, even beyond your maximum bid.\nHow it’s calculated:\n\nUses the model’s estimated coefficients to integrate the WTP distribution from 0 to infinity (or theoretically negative infinity to positive infinity depending on the model).\nIssue: May overestimate WTP, especially if the upper tail is long (which it often is).\n\n\nmedianWTP=1/sb1$coefficients[2]\nmedianWTP\n\n     BID \n-63.6041 \n\n\n\n\n\nValue: 26.04\n\nThis is the mean WTP truncated at the maximum bid in your data.\n\\(1/\\beta_{bid}(1+exp(\\beta_0+\\sum(\\beta_nZ_n)))\\)\nHow it’s calculated:\n\nIntegration is limited from 0 up to the highest bid amount offered in your survey.\nWhy: This avoids overestimating WTP from extrapolating too far beyond your data.\n\n\nmedianWTP * (log(1 + exp(sb1$coefficients[1] + sb1$coefficients[2] * max(NaturalPark$bid1))) - log(1 + exp(sb1$coefficients[1])))\n\n     BID \n26.04338 \n\n\n\n\n\n#Value: 47.27\n\nThis is the same as #2 but with a correction applied to adjust for truncation bias.\nHow it’s calculated:\n\nStill truncated at the max bid, but includes a bias-correction factor based on the distribution. the truncated mean WTP with the adjustment of Boyle et~al.(1988)\nWhy: Balances realism (truncation) with statistical accuracy (adjustment).\n\n\n\n\nValue: 34.99\n\nThis is the bid level at which 50% of respondents are predicted to say “yes”.\nHow it’s calculated:\n\\(-(\\alpha/\\beta_{bid})\\)\n\nIt’s the bid where the predicted probability of saying “yes” is 0.5, based on your model.\nWhy: Commonly used because it’s less sensitive to skewed data than the mean.\n\n\n-sb1$coefficients[1]/sb1$coefficients[2]\n\n(Intercept) \n   34.98512"
  },
  {
    "objectID": "tc.html",
    "href": "tc.html",
    "title": "Travel Cost",
    "section": "",
    "text": "CV\nDCE\nHedonic\n\n\n\n\nLost Tv GIFs - Find & Share on GIPHY"
  },
  {
    "objectID": "tc.html#we-will-be-using-this-after",
    "href": "tc.html#we-will-be-using-this-after",
    "title": "Travel Cost",
    "section": "",
    "text": "CV\nDCE\nHedonic\n\n\n\n\nLost Tv GIFs - Find & Share on GIPHY"
  },
  {
    "objectID": "hm.html",
    "href": "hm.html",
    "title": "Hedonic",
    "section": "",
    "text": "CV\nDCE"
  },
  {
    "objectID": "hm.html#this-page-will-populate-after",
    "href": "hm.html#this-page-will-populate-after",
    "title": "Hedonic",
    "section": "",
    "text": "CV\nDCE"
  },
  {
    "objectID": "rp.html",
    "href": "rp.html",
    "title": "Revealed Preference",
    "section": "",
    "text": "Stated Preferences\n\n\n\nIts So Exhausting Waiting For Death GIFs - Find & Share on GIPHY"
  },
  {
    "objectID": "rp.html#we-will-be-using-this-after",
    "href": "rp.html#we-will-be-using-this-after",
    "title": "Revealed Preference",
    "section": "",
    "text": "Stated Preferences\n\n\n\nIts So Exhausting Waiting For Death GIFs - Find & Share on GIPHY"
  },
  {
    "objectID": "sp.html",
    "href": "sp.html",
    "title": "Stated Preference",
    "section": "",
    "text": "Core Stated Preference Methods:\n\nContingent Valuation\nThis method directly asks individuals about their willingness to pay for a good or service, or their willingness to accept compensation for its loss. In R, packages can be used to analyze responses from single-bounded or double-bounded dichotomous choice CV surveys, employing both parametric and nonparametric approaches.\nDiscrete Choice\nDCEs present respondents with several choice scenarios, each containing multiple alternatives described by various attributes and their levels. Respondents choose their preferred alternative in each scenario. R packages facilitate the design of DCEs (e.g., using orthogonal main-effect designs) and the analysis of choice data using models like conditional and binary logit."
  },
  {
    "objectID": "sp.html#example",
    "href": "sp.html#example",
    "title": "Stated Preference",
    "section": "Example",
    "text": "Example\nBased on James Fogarty and Hideo Aizaki\n\nPackages\nOpen R. You will need additional packages DCchoice, Ecdat (Croissant and Graves 2020) and lmtest (Zeileis and Hothorn 2002).\n\n#install.packages(\"DCchoice\",repos = c(\"http://www.bioconductor.org/packages/release/bioc\",\"https://cran.rstudio.com/\"), dep = TRUE)\n\n#install.packages(ggplot2)\n#install.packages(dplyr)\n\nAfter installing the necessary packages, the next step is to load DCchoice, Ecdat, and lmtest into your current R session. The DCchoice package provides the core functions used in our analysis. Additionally, lmtest offers essential tools for model testing. The Ecdat package includes publicly available real-world datasets.\nFor this example, we’ll use the NaturalParks dataset to demonstrate how contingent valuation (CV) study data can be analyzed.\n\nlibrary(DCchoice)\nlibrary(Ecdat)\nlibrary(lmtest)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nLoad Data\nWe will use a built-in sample dataset from the Ecdat package. After loading the dataset, you can use the head() function to preview its contents. By default, head() displays the first six rows along with the column names, but you can adjust the number of rows shown by using the n argument. This function is a quick way to get an overview of the dataset’s structure.\n\n# Load the data from Ecdat package\ndata(NaturalPark, package = \"Ecdat\") \n\n# Display the first three rows of data          \nhead(NaturalPark, n = 5)                     \n\n  bid1 bidh bidl answers age    sex income\n1    6   18    3      yy   1 female      2\n2   48  120   24      yn   2   male      1\n3   48  120   24      yn   2 female      3\n4   24   48   12      nn   5 female      1\n5   24   48   12      ny   6 female      2\n\n\n\n\nData Variables\nThe NaturalParks (NP) dataset contains seven variables, each representing a specific aspect of the survey responses:\n\nbid1: The initial bid amount (in euros) presented in the first willingness-to-pay (WTP) question. In this dataset, there are four possible bid amounts: 6, 12, 24, and 48.\nbidh: The higher follow-up bid amount, shown only if the respondent answered “yes” to the initial WTP question.\nbidl: The lower follow-up bid amount, shown only if the respondent answered “no” to the initial WTP question.\nanswers: A factor variable representing the respondent’s answers to the two WTP questions. The four possible combinations are:\n\nnn: no to both\nny: no to first, yes to second\nyn: yes to first, no to second\nyy: yes to both\n\nSince there are four combinations, this factor variable has four levels.\n\nage: Age is grouped into six brackets rather than exact values. Higher bracket numbers correspond to older respondents.\nsex: A factor variable with two levels: “male” and “female.”\nincome: Income is also grouped into eight brackets. As with age, higher numbers represent higher income levels.\n\n\n\nData Manipulation\nThe decision identifies what each individual prefers. This is indicated by the “yes” and “no.” The variable needs to be converted into a numerical representation. To do this you will need to write a loop and create a binary indicator for when the individuals says yes to the first bid. This is indicated by the first letter of the variable starting with “y”\n\nNaturalPark$ans1 &lt;- ifelse(NaturalPark$answers == \"yy\" | NaturalPark$answers == \"yn\", 1, 0)\n\n# Display the first three rows of data          \nhead(NaturalPark, n = 5)   \n\n  bid1 bidh bidl answers age    sex income ans1\n1    6   18    3      yy   1 female      2    1\n2   48  120   24      yn   2   male      1    1\n3   48  120   24      yn   2 female      3    1\n4   24   48   12      nn   5 female      1    0\n5   24   48   12      ny   6 female      2    0\n\n\nNow we want to count the number of individuals who said yes for each price. This table shows the rows as yes or no for first bid and all the prices.\n\ntable(NaturalPark$ans1, NaturalPark$bid1) \n\n   \n     6 12 24 48\n  0 26 34 40 41\n  1 50 43 42 36\n\n\nThe table can be interpreted as follows:\n\nFor a bid price of €6, there are 76 survey responses. Out of these, 50 respondents said they would be willing to pay €6, while 26 said they would not.\nAnd so on for higher bid amounts.\n\nAs the bid price increases, we expect rationally (from law of demand) there will be a decline in the proportion of “yes” responses, since fewer people are likely to be willing to pay higher amounts for the same environmental improvement.\n\nThis pattern is visible in the table, particularly when reading across the row representing “yes” responses (often coded as 1), where the number of affirmative answers drops from 50 to 36, and continues decreasing with higher bids. Lets look at this in a graph.\n\n\nData Visualization\nTo create our demand line, we will first have to convert the data in the right shape form.\n\nyes_data &lt;- as.data.frame(table(NaturalPark$ans1, NaturalPark$bid1)) %&gt;%\n  rename(Answer = Var1, Bid = Var2, Count = Freq) %&gt;%\n  filter(Answer == 1) %&gt;%\n  mutate(Bid = as.numeric(as.character(Bid)))\n\n# Display the first three rows of data          \nhead(yes_data, n = 5)  \n\n  Answer Bid Count\n1      1   6    50\n2      1  12    43\n3      1  24    42\n4      1  48    36\n\n\nNow we will use ggplot and visually show how people respond to bid prices:\n\nggplot(yes_data, aes(x = Count, y = Bid)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  geom_point(color = \"darkgreen\", size = 3) +\n  scale_y_continuous(breaks = yes_data$Bid) +\n  labs(\n    title = \"Decline in 'Yes' Responses with Higher Bid Prices\",\n    x = \"Number of 'Yes' Responses\",\n    y = \"Bid Amount (€)\"\n  ) +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nAnd voilà! There we have a downward sloping demand curve!\nPeople respond to prices which makes sense and suggest that people are responding in a way that they do in reality.\n\n\nModel Estimation\nNow that we have explored the data and tested peoples rational. We are going to estimate the willingness to pay for the contingent valuation question.\nFor now, we’ll ignore gender, income, and age. The model assumes that a person’s response :\n\n0 (“no, not willing to pay”)\n1 (“yes, willing to pay”) depends only on the bid amount (or “price”).\n\nSo this model includes just one explanatory variable which is the bid.\nUsing DCchoice the formula for this type of model is as follows:\nmodel1 &lt;- sbchoice(dep var ~ exp var | bid, dist = \"\", data = my.data)\nHere’s what each part means:\n\nmodel1: The name we give to save the model results (for example, sb1 for the first model).\n&lt;-: The assignment symbol that stores the model in model1.\nsbchoice: The function that runs the model.\ndep_var: The dependent variable (the responses coded as 0 = no, 1 = yes). For our first model this is ans1.\nexp_var: The explanatory variables other than the bid amount. Since we don’t have any for the first model, we just use 1 for the intercept.\n| bid: This part specifies the bid amount variable, which is bid1 in our example.\ndist = \"\": Specifies the distribution used; we’ll always use logistic, so it will be dist = \"logistic\"\ndata = my.data: The data frame that contains the data which in our case is NaturalPark.\n\nAfter fitting the model, we usually check the results with the summary() function. To focus on the coefficient estimates, we can use coeftest() from the lmtest package.\n\n# A very simple model\nsb1 &lt;- sbchoice(ans1 ~ 1 | bid1,  dist = \"logistic\", data = NaturalPark)\ncoeftest(sb1)\n\n\nz test of coefficients:\n\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.5500450  0.1998739  2.7520 0.005924 **\nBID         -0.0157223  0.0071807 -2.1895 0.028560 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe most important thing to notice in the model’s coefficients is the negative sign on the bid variable. No matter how the original data is coded, the bid will always show up as BID in the results. This negative sign means that as the bid price goes up, fewer people say “yes” they are less willing to pay that amount!\nThe results also show that this relationship is statistically significant, meaning it’s unlikely to be due to chance.\nLets see these results visually by using the plot() function. This plot shows the willingness-to-pay data along with a horizontal line marking the point where 50% of people say “yes.” From the plot, you can see that this 50% support happens at about €35.\n\n# plots the predicted support at each bid value \nplot(sb1, las = 1)  \n\n# adds a horizontal line to the plot \nabline(h = 0.5, lty = 2, col = \"red\") \n\n\n\n\n\n\n\n\n\n\nFull Estimation\nWe now look at the full model summary output we get when we use the sbchoice() function:\n\n#  Model summary\nsummary(sb1) \n\n\nCall:\nsbchoice(formula = ans1 ~ 1 | bid1, data = NaturalPark, dist = \"logistic\")\n\nFormula:\nans1 ~ 1 | bid1\n\nCoefficients: \n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.550045   0.199874   2.752  0.00592 **\nBID         -0.015722   0.007181  -2.190  0.02856 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nDistribution: logistic \nNumber of Obs.: 312  \nlog-likelihood: -212.3968 \npseudo-R^2: 0.0113 , adjusted pseudo-R^2: 0.0020 \nLR statistic: 4.841 on 1 DF, p-value: 0.028 \nAIC: 428.793653 , BIC: 436.279659 \n\nIterations: 4  \nConvergence: TRUE \n\nWTP estimates:\n Mean : 63.95526 \n Mean : 26.04338 (truncated at the maximum bid)\n Mean : 47.26755 (truncated at the maximum bid with adjustment)\n Median : 34.98512 \n\n\nThe summary output has several parts:\n\nThe model we estimated:\nFormula:\nans1 ~ 1 | bid1\n\nCoefficients: \n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.550045   0.199874   2.752  0.00592 **\nBID         -0.015722   0.007181  -2.190  0.02856 * \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\nThe second part shows the model’s coefficients and whether they are statistically significant.\nDistribution: logistic \nNumber of Obs.: 312  \nlog-likelihood: -212.3968 \npseudo-R^2: 0.0113 , adjusted pseudo-R^2: 0.0020 \nLR statistic: 4.841 on 1 DF, p-value: 0.028 \nAIC: 428.793653 , BIC: 436.279659 \nThe third part shows how well the model fits the data. This helps us compare different models. It’s important to see “Convergence: TRUE,” which means the model worked properly. If not, you’ll get an error.\nIterations: 4  \nConvergence: TRUE \nThe fourth part shows the estimated average and median willingness to pay (WTP). Lets take a moment here\nWTP estimates:\n Mean : 63.95526 \n Mean : 26.04338 (truncated at the maximum bid)\n Mean : 47.26755 (truncated at the maximum bid with adjustment)\n Median : 34.98512 \n\n\n1. Mean WTP\nValue: Value: 63.95\nThis estimate can be calculated by taking the coefficient of the estimation on bid:\n\\(1/\\beta_{bid} = 1/-0.015722=63.95\\)\nThis is the unbounded mean and its calculated using the full range of the estimated distribution of WTP, even beyond your maximum bid.\nHow it’s calculated:\n\nUses the model’s estimated coefficients to integrate the WTP distribution from 0 to infinity (or theoretically negative infinity to positive infinity depending on the model).\nIssue: May overestimate WTP, especially if the upper tail is long (which it often is).\n\n\nmedianWTP=1/sb1$coefficients[2]\nmedianWTP\n\n     BID \n-63.6041 \n\n\n\n\n2. Mean WTP (truncated at max bid)\nValue: 26.04\n\nThis is the mean WTP truncated at the maximum bid in your data.\n\\(1/\\beta_{bid}(1+exp(\\beta_0+\\sum(\\beta_nZ_n)))\\)\nHow it’s calculated:\n\nIntegration is limited from 0 up to the highest bid amount offered in your survey.\nWhy: This avoids overestimating WTP from extrapolating too far beyond your data.\n\n\nmedianWTP * (log(1 + exp(sb1$coefficients[1] + sb1$coefficients[2] * max(NaturalPark$bid1))) - log(1 + exp(sb1$coefficients[1])))\n\n     BID \n26.04338 \n\n\n\n\n3. Mean WTP (truncated with adjustment)\nValue: 47.27\n\nThis is the same as #2 but with a correction applied to adjust for truncation bias.\nHow it’s calculated:\n\nStill truncated at the max bid, but includes a bias-correction factor based on the distribution. the truncated mean WTP with the adjustment of Boyle et~al.(1988)\nWhy: Balances realism (truncation) with statistical accuracy (adjustment).\n\n\n\n4. Median WTP\nValue: 34.99\n\nThis is the bid level at which 50% of respondents are predicted to say “yes”.\nHow it’s calculated:\n\\(-(\\alpha/\\beta_{bid})\\)\n\nIt’s the bid where the predicted probability of saying “yes” is 0.5, based on your model.\nWhy: Commonly used because it’s less sensitive to skewed data than the mean.\n\n\n-sb1$coefficients[1]/sb1$coefficients[2]\n\n(Intercept) \n   34.98512"
  },
  {
    "objectID": "sp.html#attribute-levels",
    "href": "sp.html#attribute-levels",
    "title": "Stated Preference",
    "section": "Attribute & Levels",
    "text": "Attribute & Levels\n\n\n\n\n\n\n\n\nAttributes\nLabels\nLevels\n\n\n\n\nSize of Wind Farm (discrete)\nSmall Farms\n0\n\n\nNote reference is LargeFarm\n\n1\n\n\n\nMediumFarms\n0\n\n\n\n\n1\n\n\nMax. Height Turbine (discrete)\nLow Height\n0\n\n\nNote reference is HighHeight\n\n1\n\n\n\nMedium Height\n0\n\n\n\n\n1\n\n\nReduction in Red Kite (continous)\nRed Kite\n5\n\n\n\n\n7.5\n\n\n\n\n10\n\n\n\n\n12.5\n\n\n\n\n15\n\n\nDistance to residents (continous)\nMinDistance\n750\n\n\n\n\n1000\n\n\n\n\n1250\n\n\n\n\n1500\n\n\n\n\n1750\n\n\nMonthlyCost\n(Continous)\nCost\n0\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n…..\n\n\n\n\n….\n\n\n\n\n10"
  },
  {
    "objectID": "sp.html#choice-set",
    "href": "sp.html#choice-set",
    "title": "Stated Preference",
    "section": "Choice Set",
    "text": "Choice Set\nLets first consider this example\n\nThis choice card has 3 alternatives and thus 3 different utility functions you are estimating:\n\nThe status quo or the opting out and keeping things the way they are. The utility function would look something like this:\n\n\\[\nU_{n1t}=\n\\beta_{mf}Med.Farms_{n1t}+\\beta_{sf}SmallFarms_{n1t} \\\\\n+\\beta_{mh}Med.Height_{n1t}+\\beta_{lh}LowHeight_{n1t} \\\\\n+\\beta_{rk}redKite_{n|t}+\\beta_{md}MinDistance_{n1t} \\\\\n\\beta_{cost}Cost_{n1t}+ \\epsilon_{n1t}\n\\]\n\nProgram B will be alternative 2 and thus is indexed by 2\n\n\\[\nU_{n2t}= \\beta_{mf}Med.Farms_{n2t}+\\beta_{sf}SmallFarms_{n2t} \\\\\n+\\beta_{mh}Med.Height_{n2t}+\\beta_{lh}LowHeight_{n2t} \\\\\n+\\beta_{rk}redKite_{n2t}+\\beta_{md}MinDistance_{n2t} \\\\\n\\beta_{cost}Cost_{n2t}+ \\epsilon_{n2t}\n\\]\n\nProgram C will be alternative 3 and thus is indexed by 3\n\\[\nU_{n3t}= \\beta_{mf}Med.Farms_{n3t}+\\beta_{sf}SmallFarms_{n3t} \\\\\n+\\beta_{mh}Med.Height_{n3t}+\\beta_{lh}LowHeight_{n3t} \\\\\n+\\beta_{rk}redKite_{n3t}+\\beta_{md}MinDistance_{n3t} \\\\\n\\beta_{cost}Cost_{n3t}+ \\epsilon_{n3t}\n\\]"
  },
  {
    "objectID": "sp.html#experiential-design",
    "href": "sp.html#experiential-design",
    "title": "Stated Preference",
    "section": "Experiential Design",
    "text": "Experiential Design\nWe will now look at a full factorial design for the entire choice set and all the levels. Given the choices above the amount of possible combinations balloons to 5mil+ observations!\n\n# Create the full factorial using a named list of attributes and levels in the wide format\nfull_fact &lt;- full_factorial( list( alt1_sq = 1,\nalt1_farm = 0,\nalt1_height = 0,\nalt1_redkite = 0,\nalt1_distance = 0,\nalt1_cost = 0,\nalt2_sq = 0,\nalt2_farm = c(1, 2, 3),\nalt2_height = c(1, 2, 3),\nalt2_redkite = c(-5, -2.5, 0, 2.5, 5), alt2_distance = c(0, 0.25, 0.5, 0.75, 1), alt2_cost = 1:10,\nalt3_sq = 0,\nalt3_farm = c(1, 2, 3),\nalt3_height = c(1, 2, 3),\nalt3_redkite = c(-5, -2.5, 0, 2.5, 5), alt3_distance = c(0, 0.25, 0.5, 0.75, 1), alt3_cost = 1:10\n) )\n\n# Show the first six rows and 8th to 12th columns of the design matrix\nfull_fact[1:6, c(1, 8:12)]\n\n  alt1_sq alt2_farm alt2_height alt2_redkite alt2_distance alt2_cost\n1       1         1           1           -5             0         1\n2       1         2           1           -5             0         1\n3       1         3           1           -5             0         1\n4       1         1           2           -5             0         1\n5       1         2           2           -5             0         1\n6       1         3           2           -5             0         1\n\n\nAs the number of attributes, levels, and alternatives increases, full factorial designs become less practical for several reasons:\n\nDuplicate alternatives: Some choice tasks may repeat the same alternative, which doesn’t help us learn anything new about preferences.\nDominated alternatives: Some options in a choice task might be clearly worse (or better) than others in every way. These don’t help reveal trade-offs because people will always pick the best one, making the data less useful.\nLack of control: The full factorial includes all possible combinations, even unrealistic ones. For example, we might want to prevent small wind farms from showing up with the highest red kite impact.\n\n\nLogical Operators\nLets say we want to put restriction by putting logical restrictions. For example, the tall windmills cannot be placed too close to residential areas (this could already be a law and thus is a more accurate reflection of reality).\n\ncandidate_set &lt;- full_fact[!((full_fact$alt2_height == 1 & full_fact$alt2_distance &lt; 0.75) | (full_fact$alt3_height == 1 & full_fact$alt3_distance &lt; 0.75)), ]\n\ncandidate_set[1:6, c(1, 8:12)]\n\n     alt1_sq alt2_farm alt2_height alt2_redkite alt2_distance alt2_cost\n6754       1         1           2           -5             0         1\n6755       1         2           2           -5             0         1\n6756       1         3           2           -5             0         1\n6757       1         1           3           -5             0         1\n6758       1         2           3           -5             0         1\n6759       1         3           3           -5             0         1\n\n\nThis reduces the number of observations to 3.2million+ but does not make our choice set reasonable for population sampling. There for we move onto the next approach D-efficient\n\n\nD-efficient Design\nIn statistics, we often try to reduce standard errors to improve the precision of our estimates. The same idea applies in Discrete Choice Experiments (DCEs). We want to design choice tasks that give us the most precise information.\nThink of it this way:\n\nWhen fitting a model, we already have the data and estimate the parameters that best explain it.\nWhen designing a DCE, we do the reverse: we assume values for the parameters (called priors) and then search for the combination of attributes and levels that will give us the most information — that is, the lowest standard errors or lowest D-error.\n\n\n\nUtility Function\nFor our example we need to design a utility function to estimate the best set of potential choice cards. The utility function was written out within choice set section. So here we are going to use the library spdesign to write out each alternative.\n\nutility &lt;- list(\nalt1 = \"b_sq[0] * sq[1]\",\nalt2 = \"b_farm_dummy[c(0.25, 0.5)] * farm[c(1, 2, 3)] +\nb_height_dummy[c(0.25, 0.5)] * height[c(1, 2, 3)] + b_redkite[-0.05] * redkite[c(-5, -2.5, 0, 2.5, 5)] + b_distance[0.5] * distance[c(0, 0.25, 0.5, 0.75, 1)] + b_cost[-0.05] * cost[seq(1, 10)]\",\nalt3 = \"b_farm_dummy * farm + b_height_dummy * height +\nb_redkite * redkite + b_distance * distance + b_cost * cost\"\n)\n\n\n\nGenerating Design\nIn library spdesign generate_designis a function that generates efficient experimental designs. The function takes a set of indirect utility functions and generates efficient experimental designs assuming that people are maximizing utility.\nHere are the arguments needed for our example:\n\n\n\n\n\n\n\nutility\nA named list of utility functions. See the examples and the vignette for examples of how to define these correctly for different types of experimental designs.\n\n\nrows\nAn integer giving the number of rows in the final design\n\n\nmodel\nA character string indicating the model to optimize the design for. Currently the only model programmed is the ‘mnl’ model and this is also set as the default.\n\n\nefficiency_criteria\nA character string giving the efficiency criteria to optimize for. One of ‘a-error’, ‘c-error’, ‘d-error’ or ‘s-error’. No default is set and argument must be specified. Optimizing for multiple criteria is not yet implemented and will result in an error.\n\n\nalgorithm\nA character string giving the optimization algorithm to use. No default is set and the argument must be specified to be one of ‘rsc’, ‘federov’ or ‘random’.\n\n\n\n\n# Generate design ----\ndesign &lt;- generate_design(utility, rows = 100,\nmodel = \"mnl\", efficiency_criteria = \"d-error\", algorithm = \"rsc\")\n\n\n\n\n── Checking function arguments ──\n\n\n\n\n\nℹ The cycling part of the algorithm is not used. It only applies to a\nsmall subset of designs. The algorithm swithes between relabeling of\nattribute levels and swapping of attributes.\n\n\n\n\n\n── Preparing the list of priors ──\n\n\n\n\n\n✔ Priors prepared successfully\n\n\n\n\n\n── Evaluating designs ──────────────────────────────────────────────────────────\n\n\n\n──────────────────────────────────────────────────────────────────────────────── \n Iteration   A-error   C-error   D-error   S-error               Time stamp\n──────────────────────────────────────────────────────────────────────────────── \n         1    0.1326       N/A    0.0422       Inf2025-09-20 21:46:18.258879\n──────────────────────────────────────────────────────────────────────────── \n\n\nℹ Efficiency criteria is less than threshhold.\n\n\n\n\n\n── Cleaning up design environment ──────────────────────────────────────────────\n\n\nTime spent searching for designs:  0.06388807 \n\n\n\nsummary(design)\n\n---------------------------------------------------------------------\nAn 'spdesign' object\n\nUtility functions:\nalt1 : b_sq * alt1_sq \nalt2 : b_farm_dummy * alt2_farm + b_height_dummy * alt2_height + b_redkite * alt2_redkite + b_distance * alt2_distance + b_cost * alt2_cost \nalt3 : b_farm_dummy * alt3_farm + b_height_dummy * alt3_height + b_redkite * alt3_redkite + b_distance * alt3_distance + b_cost * alt3_cost \n\n\n   a-error    c-error    d-error    s-error \n0.13261146        NaN 0.04218168        Inf \n\n---------------------------------------------------------------------\n\nPrinting the first few rows of the design \n# A tibble: 6 × 15\n  alt1_sq alt2_farm2 alt2_farm3 alt2_height2 alt2_height3 alt2_redkite\n    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1       1          0          0            0            0          5  \n2       1          0          0            1            0         -5  \n3       1          0          0            0            0         -2.5\n4       1          1          0            1            0          2.5\n5       1          1          0            0            1          5  \n6       1          0          1            0            0          0  \n# ℹ 9 more variables: alt2_distance &lt;dbl&gt;, alt2_cost &lt;dbl&gt;, alt3_farm2 &lt;dbl&gt;,\n#   alt3_farm3 &lt;dbl&gt;, alt3_height2 &lt;dbl&gt;, alt3_height3 &lt;dbl&gt;,\n#   alt3_redkite &lt;dbl&gt;, alt3_distance &lt;dbl&gt;, alt3_cost &lt;dbl&gt;\n\n---------------------------------------------------------------------\n\n\n\n\nCorrelation\nNext step check correlation\n\n# Correlation matrix\ncor(design)\n\nWarning in stats::cor(x[[\"design\"]], y = NULL, use = \"everything\", method =\nc(\"pearson\", : the standard deviation is zero\n\n\n              alt1_sq  alt2_farm2   alt2_farm3  alt2_height2 alt2_height3\nalt1_sq             1          NA           NA            NA           NA\nalt2_farm2         NA  1.00000000 -0.503717523 -9.966603e-02  0.197860963\nalt2_farm3         NA -0.50371752  1.000000000  4.975124e-03  0.035017796\nalt2_height2       NA -0.09966603  0.004975124  1.000000e+00 -0.503717523\nalt2_height3       NA  0.19786096  0.035017796 -5.037175e-01  1.000000000\nalt2_redkite       NA  0.02985407  0.060152076  1.503802e-02 -0.074635179\nalt2_distance      NA  0.10448925 -0.105266133 -7.519010e-02 -0.044781108\nalt2_cost          NA  0.11024347  0.099956818 -5.553157e-02  0.051446951\nalt3_farm2         NA  0.03501780 -0.085481682  9.543193e-02  0.124807016\nalt3_farm3         NA -0.11408200  0.079912406  7.991241e-02 -0.114081996\nalt3_height2       NA  0.06417112 -0.054771424 -1.445606e-01  0.019607843\nalt3_height3       NA  0.03501780 -0.175938489  4.975124e-03 -0.009876814\nalt3_redkite       NA -0.11941629  0.195494248  1.335644e-17  0.149270359\nalt3_distance      NA -0.02985407 -0.105266133  1.654182e-01 -0.179124430\nalt3_cost          NA  0.04409739  0.099956818 -1.147652e-01  0.183739110\n              alt2_redkite alt2_distance    alt2_cost  alt3_farm2   alt3_farm3\nalt1_sq                 NA            NA           NA          NA           NA\nalt2_farm2      0.02985407    0.10448925  0.110243466  0.03501780 -0.114081996\nalt2_farm3      0.06015208   -0.10526613  0.099956818 -0.08548168  0.079912406\nalt2_height2    0.01503802   -0.07519010 -0.055531566  0.09543193  0.079912406\nalt2_height3   -0.07463518   -0.04478111  0.051446951  0.12480702 -0.114081996\nalt2_redkite    1.00000000    0.17500000  0.194484556 -0.04511406 -0.014927036\nalt2_distance   0.17500000    1.00000000 -0.073854895  0.03007604  0.029854072\nalt2_cost       0.19448456   -0.07385489  1.000000000 -0.04812736  0.007349564\nalt3_farm2     -0.04511406    0.03007604 -0.048127357  1.00000000 -0.503717523\nalt3_farm3     -0.01492704    0.02985407  0.007349564 -0.50371752  1.000000000\nalt3_height2   -0.08956222   -0.02985407 -0.051446951  0.03501780 -0.158645276\nalt3_height3    0.10526613    0.21053227  0.144382071 -0.04025328  0.169701625\nalt3_redkite   -0.09000000   -0.02000000  0.054160256  0.12030415 -0.119416287\nalt3_distance  -0.05000000   -0.05000000 -0.128015151 -0.07519010 -0.044781108\nalt3_cost       0.03938928    0.11570600  0.031515152  0.06293577  0.044097386\n              alt3_height2 alt3_height3  alt3_redkite alt3_distance   alt3_cost\nalt1_sq                 NA           NA            NA            NA          NA\nalt2_farm2      0.06417112  0.035017796 -1.194163e-01   -0.02985407  0.04409739\nalt2_farm3     -0.05477142 -0.175938489  1.954942e-01   -0.10526613  0.09995682\nalt2_height2   -0.14456064  0.004975124  1.335644e-17    0.16541821 -0.11476524\nalt2_height3    0.01960784 -0.009876814  1.492704e-01   -0.17912443  0.18373911\nalt2_redkite   -0.08956222  0.105266133 -9.000000e-02   -0.05000000  0.03938928\nalt2_distance  -0.02985407  0.210532267 -2.000000e-02   -0.05000000  0.11570600\nalt2_cost      -0.05144695  0.144382071  5.416026e-02   -0.12801515  0.03151515\nalt3_farm2      0.03501780 -0.040253279  1.203042e-01   -0.07519010  0.06293577\nalt3_farm3     -0.15864528  0.169701625 -1.194163e-01   -0.04478111  0.04409739\nalt3_height2    1.00000000 -0.503717523 -1.641974e-01    0.01492704 -0.09554434\nalt3_height3   -0.50371752  1.000000000  4.511406e-02    0.01503802  0.03331894\nalt3_redkite   -0.16419739  0.045114057  1.000000e+00    0.12500000  0.07385489\nalt3_distance   0.01492704  0.015038019  1.250000e-01    1.00000000 -0.20925553\nalt3_cost      -0.09554434  0.033318939  7.385489e-02   -0.20925553  1.00000000\n\n\n\n\nAttribute Balance\n\n# Print only the first three list elements\nlevel_balance(design)[1:3]\n\n$alt1_sq\n\n  1 \n100 \n\n$alt2_farm2\n\n 0  1 \n66 34 \n\n$alt2_farm3\n\n 0  1 \n67 33 \n\n\nFirst, we can see that the constant for the status quo alternative appears in all 100 rows of the design. Next, the medium and small wind farm sizes each occur 33 times, meaning the large size appears 34 times. This suggests the design is nearly balanced across attribute levels.\n\n\nDominated Strategy Check\nDominant or dominated alternatives should be avoided because they don't provide useful information about trade-offs and can bias your results.\nTo check for this, we can look at the choice probabilities for each alternative. If one option has a probability close to 1, it likely dominates the others. If it's close to 0, it's probably dominated.\nThe spdesign package includes a probabilities() function that calculates these values based on your design and priors. It shows the probability of choosing each alternative in every choice task. Each row of the output adds up to 1.\n\n# Check the utility balance by inspecting the probabilities. We use head() to avoid printing all 100 rows in the book.\nprobabilities(design) |&gt;\nhead()\n\n          alt1      alt2      alt3\n[1,] 0.2481340 0.2882906 0.4635754\n[2,] 0.2280426 0.3666958 0.4052615\n[3,] 0.2538738 0.2949593 0.4511669\n[4,] 0.2474358 0.5646189 0.1879453\n[5,] 0.3598675 0.3598675 0.2802651\n[6,] 0.2930275 0.3579046 0.3490679"
  },
  {
    "objectID": "dce.html",
    "href": "dce.html",
    "title": "Discrete Choice Experiment",
    "section": "",
    "text": "Discrete Choice Experiements (DCEs) ( present respondents with several choice scenarios, each containing multiple alternatives described by various attributes and their levels. Respondents choose their preferred alternative in each scenario. R packages facilitate the design of DCEs (e.g., using orthogonal main-effect designs) and the analysis of choice data using models like conditional and binary logit.\nFor our example we will be using this book\nEnvironmental Valuation with Discrete Choice Experiments in R\nThese are the libraries you need to run the code below:\n\n# Note if you don't have packages install.packages(\"put library name in here\")\nlibrary(Rfast)\nlibrary(spdesign)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(tibble)\n\nWe will use the example the above book uses through out the chapters.\n\n\n\n\n\n\n\n\n\n\nAttributes\nLabels\nLevels\n\n\n\n\nSize of Wind Farm (discrete)\nSmall Farms\n0\n\n\nNote reference is LargeFarm\n\n1\n\n\n\nMediumFarms\n0\n\n\n\n\n1\n\n\nMax. Height Turbine (discrete)\nLow Height\n0\n\n\nNote reference is HighHeight\n\n1\n\n\n\nMedium Height\n0\n\n\n\n\n1\n\n\nReduction in Red Kite (continous)\nRed Kite\n5\n\n\n\n\n7.5\n\n\n\n\n10\n\n\n\n\n12.5\n\n\n\n\n15\n\n\nDistance to residents (continous)\nMinDistance\n750\n\n\n\n\n1000\n\n\n\n\n1250\n\n\n\n\n1500\n\n\n\n\n1750\n\n\nMonthlyCost\n(Continous)\nCost\n0\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n…..\n\n\n\n\n….\n\n\n\n\n10\n\n\n\n\n\n\nLets first consider this example\n\nThis choice card has 3 alternatives and thus 3 different utility functions you are estimating:\n\nThe status quo or the opting out and keeping things the way they are. The utility function would look something like this:\n\n\\[\n\\begin{aligned}\nU_{n1t} =\\; & \\beta_{mf} \\, Med.Farms_{n1t} + \\beta_{sf} \\, SmallFarms_{n1t} \\\\& + \\beta_{mh} \\, Med.Height_{n1t} + \\beta_{lh}\n\\, LowHeight_{n1t} \\\\& + \\beta_{rk} \\, redKite_{n|t} + \\beta_{md} \\, MinDistance_{n1t} \\\\& + \\beta_{cost} \\, Cost_{n1t} + \\epsilon_{n1t}\n\\end{aligned}\n\\]\n\nProgram B will be alternative 2 and thus is indexed by 2\n\n\\[\n\\begin{aligned}\nU_{n2t}= \\beta_{mf}Med.Farms_{n2t}+\\beta_{sf}SmallFarms_{n2t} \\\\\n+\\beta_{mh}Med.Height_{n2t}+\\beta_{lh}LowHeight_{n2t} \\\\\n+\\beta_{rk}redKite_{n2t}+\\beta_{md}MinDistance_{n2t} \\\\\n\\beta_{cost}Cost_{n2t}+ \\epsilon_{n2t} \\\\\n\\end{aligned}\n\\]\n\nProgram C will be alternative 3 and thus is indexed by 3\n\\[\n\\begin{aligned}\nU_{n3t}= \\beta_{mf}Med.Farms_{n3t}+\\beta_{sf}SmallFarms_{n3t} \\\\\n+\\beta_{mh}Med.Height_{n3t}+\\beta_{lh}LowHeight_{n3t} \\\\\n+\\beta_{rk}redKite_{n3t}+\\beta_{md}MinDistance_{n3t} \\\\\n\\beta_{cost}Cost_{n3t}+ \\epsilon_{n3t} \\\\\n\\end{aligned}\n\\]\n\n\n\n\nWe will now look at a full factorial design for the entire choice set and all the levels. Given the choices above the amount of possible combinations balloons to 5mil+ observations!\n\n# Create the full factorial using a named list of attributes and levels in the wide format\nfull_fact &lt;- full_factorial( list( alt1_sq = 1,\nalt1_farm = 0,\nalt1_height = 0,\nalt1_redkite = 0,\nalt1_distance = 0,\nalt1_cost = 0,\nalt2_sq = 0,\nalt2_farm = c(1, 2, 3),\nalt2_height = c(1, 2, 3),\nalt2_redkite = c(-5, -2.5, 0, 2.5, 5), alt2_distance = c(0, 0.25, 0.5, 0.75, 1), alt2_cost = 1:10,\nalt3_sq = 0,\nalt3_farm = c(1, 2, 3),\nalt3_height = c(1, 2, 3),\nalt3_redkite = c(-5, -2.5, 0, 2.5, 5), alt3_distance = c(0, 0.25, 0.5, 0.75, 1), alt3_cost = 1:10\n) )\n\n# Show the first six rows and 8th to 12th columns of the design matrix\nfull_fact[1:6, c(1, 8:12)]\n\n  alt1_sq alt2_farm alt2_height alt2_redkite alt2_distance alt2_cost\n1       1         1           1           -5             0         1\n2       1         2           1           -5             0         1\n3       1         3           1           -5             0         1\n4       1         1           2           -5             0         1\n5       1         2           2           -5             0         1\n6       1         3           2           -5             0         1\n\n\nAs the number of attributes, levels, and alternatives increases, full factorial designs become less practical for several reasons:\n\nDuplicate alternatives: Some choice tasks may repeat the same alternative, which doesn’t help us learn anything new about preferences.\nDominated alternatives: Some options in a choice task might be clearly worse (or better) than others in every way. These don’t help reveal trade-offs because people will always pick the best one, making the data less useful.\nLack of control: The full factorial includes all possible combinations, even unrealistic ones. For example, we might want to prevent small wind farms from showing up with the highest red kite impact.\n\n\n\nLets say we want to put restriction by putting logical restrictions. For example, the tall windmills cannot be placed too close to residential areas (this could already be a law and thus is a more accurate reflection of reality).\n\ncandidate_set &lt;- full_fact[!((full_fact$alt2_height == 1 & full_fact$alt2_distance &lt; 0.75) | (full_fact$alt3_height == 1 & full_fact$alt3_distance &lt; 0.75)), ]\n\ncandidate_set[1:6, c(1, 8:12)]\n\n     alt1_sq alt2_farm alt2_height alt2_redkite alt2_distance alt2_cost\n6754       1         1           2           -5             0         1\n6755       1         2           2           -5             0         1\n6756       1         3           2           -5             0         1\n6757       1         1           3           -5             0         1\n6758       1         2           3           -5             0         1\n6759       1         3           3           -5             0         1\n\n\nThis reduces the number of observations to 3.2million+ but does not make our choice set reasonable for population sampling. There for we move onto the next approach D-efficient\n\n\n\nIn statistics, we often try to reduce standard errors to improve the precision of our estimates. The same idea applies in Discrete Choice Experiments (DCEs). We want to design choice tasks that give us the most precise information.\nThink of it this way:\n\nWhen fitting a model, we already have the data and estimate the parameters that best explain it.\nWhen designing a DCE, we do the reverse: we assume values for the parameters (called priors) and then search for the combination of attributes and levels that will give us the most information — that is, the lowest standard errors or lowest D-error.\n\n\n\n\nFor our example we need to design a utility function to estimate the best set of potential choice cards. The utility function was written out within choice set section. So here we are going to use the library spdesign to write out each alternative.\n\nutility &lt;- list(\nalt1 = \"b_sq[0] * sq[1]\",\nalt2 = \"b_farm_dummy[c(0.25, 0.5)] * farm[c(1, 2, 3)] +\nb_height_dummy[c(0.25, 0.5)] * height[c(1, 2, 3)] + b_redkite[-0.05] * redkite[c(-5, -2.5, 0, 2.5, 5)] + b_distance[0.5] * distance[c(0, 0.25, 0.5, 0.75, 1)] + b_cost[-0.05] * cost[seq(1, 10)]\",\nalt3 = \"b_farm_dummy * farm + b_height_dummy * height +\nb_redkite * redkite + b_distance * distance + b_cost * cost\"\n)\n\n\n\n\nIn library spdesign generate_designis a function that generates efficient experimental designs. The function takes a set of indirect utility functions and generates efficient experimental designs assuming that people are maximizing utility.\nHere are the arguments needed for our example:\n\n\n\n\n\n\n\nutility\nA named list of utility functions. See the examples and the vignette for examples of how to define these correctly for different types of experimental designs.\n\n\nrows\nAn integer giving the number of rows in the final design\n\n\nmodel\nA character string indicating the model to optimize the design for. Currently the only model programmed is the ‘mnl’ model and this is also set as the default.\n\n\nefficiency_criteria\nA character string giving the efficiency criteria to optimize for. One of ‘a-error’, ‘c-error’, ‘d-error’ or ‘s-error’. No default is set and argument must be specified. Optimizing for multiple criteria is not yet implemented and will result in an error.\n\n\nalgorithm\nA character string giving the optimization algorithm to use. No default is set and the argument must be specified to be one of ‘rsc’, ‘federov’ or ‘random’.\n\n\n\n\n\n\n──────────────────────────────────────────────────────────────────────────────── \n Iteration   A-error   C-error   D-error   S-error               Time stamp\n──────────────────────────────────────────────────────────────────────────────── \n         1    0.1322       N/A    0.0423       Inf2025-09-20 21:19:06.380483\n──────────────────────────────────────────────────────────────────────────── \n\n\nTime spent searching for designs:  0.05410409 \n\n\n\nsummary(design)\n\n---------------------------------------------------------------------\nAn 'spdesign' object\n\nUtility functions:\nalt1 : b_sq * alt1_sq \nalt2 : b_farm_dummy * alt2_farm + b_height_dummy * alt2_height + b_redkite * alt2_redkite + b_distance * alt2_distance + b_cost * alt2_cost \nalt3 : b_farm_dummy * alt3_farm + b_height_dummy * alt3_height + b_redkite * alt3_redkite + b_distance * alt3_distance + b_cost * alt3_cost \n\n\n   a-error    c-error    d-error    s-error \n0.13218255        NaN 0.04234627        Inf \n\n---------------------------------------------------------------------\n\nPrinting the first few rows of the design \n# A tibble: 6 × 15\n  alt1_sq alt2_farm2 alt2_farm3 alt2_height2 alt2_height3 alt2_redkite\n    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1       1          0          0            0            0          0  \n2       1          0          0            1            0         -2.5\n3       1          0          0            1            0         -2.5\n4       1          1          0            0            1         -5  \n5       1          0          0            0            1          2.5\n6       1          1          0            0            0          2.5\n# ℹ 9 more variables: alt2_distance &lt;dbl&gt;, alt2_cost &lt;dbl&gt;, alt3_farm2 &lt;dbl&gt;,\n#   alt3_farm3 &lt;dbl&gt;, alt3_height2 &lt;dbl&gt;, alt3_height3 &lt;dbl&gt;,\n#   alt3_redkite &lt;dbl&gt;, alt3_distance &lt;dbl&gt;, alt3_cost &lt;dbl&gt;\n\n---------------------------------------------------------------------\n\n\n\n\n\nNext step check correlation\n\n# Correlation matrix\ncor(design)\n\nWarning in stats::cor(x[[\"design\"]], y = NULL, use = \"everything\", method =\nc(\"pearson\", : the standard deviation is zero\n\n\n              alt1_sq    alt2_farm2  alt2_farm3  alt2_height2 alt2_height3\nalt1_sq             1            NA          NA            NA           NA\nalt2_farm2         NA  1.000000e+00 -0.50371752 -4.025328e-02 -0.085481682\nalt2_farm3         NA -5.037175e-01  1.00000000 -5.477142e-02  0.124807016\nalt2_height2       NA -4.025328e-02 -0.05477142  1.000000e+00 -0.492537313\nalt2_height3       NA -8.548168e-02  0.12480702 -4.925373e-01  1.000000000\nalt2_redkite       NA  1.335644e-18 -0.10448925  9.022811e-02 -0.150380191\nalt2_distance      NA  3.007604e-02 -0.11941629 -9.022811e-02  0.060152076\nalt2_cost          NA -7.774419e-02  0.01469913  9.255261e-02 -0.166594697\nalt3_farm2         NA  1.406603e-01 -0.05477142  5.020353e-02  0.140660335\nalt3_farm3         NA -9.966603e-02  0.06417112 -9.876814e-03 -0.099666034\nalt3_height2       NA -8.548168e-02  0.12480702 -1.759385e-01  0.095431931\nalt3_height3       NA -1.894553e-01  0.15329768 -9.876814e-03 -0.009876814\nalt3_redkite       NA  7.519010e-02 -0.11941629  3.007604e-02 -0.015038019\nalt3_distance      NA -6.015208e-02  0.01492704  3.339111e-18 -0.105266133\nalt3_cost          NA -1.888073e-01  0.14699129 -1.851052e-02 -0.033318939\n               alt2_redkite alt2_distance   alt2_cost  alt3_farm2   alt3_farm3\nalt1_sq                  NA            NA          NA          NA           NA\nalt2_farm2     1.335644e-18  3.007604e-02 -0.07774419  0.14066033 -0.099666034\nalt2_farm3    -1.044893e-01 -1.194163e-01  0.01469913 -0.05477142  0.064171123\nalt2_height2   9.022811e-02 -9.022811e-02  0.09255261  0.05020353 -0.009876814\nalt2_height3  -1.503802e-01  6.015208e-02 -0.16659470  0.14066033 -0.099666034\nalt2_redkite   1.000000e+00 -4.500000e-02  0.10093502  0.04511406 -0.089562215\nalt2_distance -4.500000e-02  1.000000e+00  0.12062966 -0.12030415 -0.044781108\nalt2_cost      1.009350e-01  1.206297e-01  1.00000000  0.02591473 -0.132292159\nalt3_farm2     4.511406e-02 -1.203042e-01  0.02591473  1.00000000 -0.503717523\nalt3_farm3    -8.956222e-02 -4.478111e-02 -0.13229216 -0.50371752  1.000000000\nalt3_height2   4.511406e-02  1.836511e-17 -0.16659470 -0.04025328 -0.009876814\nalt3_height3  -8.956222e-02  8.956222e-02  0.09554434  0.03501780  0.019607843\nalt3_redkite   1.100000e-01  1.450000e-01 -0.05662209 -0.12030415  0.029854072\nalt3_distance  0.000000e+00  4.000000e-02  0.05416026  0.01503802 -0.119416287\nalt3_cost     -1.452480e-01 -6.154575e-02 -0.17696970 -0.21101995  0.110243466\n               alt3_height2 alt3_height3 alt3_redkite alt3_distance   alt3_cost\nalt1_sq                  NA           NA           NA            NA          NA\nalt2_farm2    -8.548168e-02 -0.189455254   0.07519010 -6.015208e-02 -0.18880732\nalt2_farm3     1.248070e-01  0.153297683  -0.11941629  1.492704e-02  0.14699129\nalt2_height2  -1.759385e-01 -0.009876814   0.03007604  3.339111e-18 -0.01851052\nalt2_height3   9.543193e-02 -0.009876814  -0.01503802 -1.052661e-01 -0.03331894\nalt2_redkite   4.511406e-02 -0.089562215   0.11000000  0.000000e+00 -0.14524796\nalt2_distance  1.836511e-17  0.089562215   0.14500000  4.000000e-02 -0.06154575\nalt2_cost     -1.665947e-01  0.095544337  -0.05662209  5.416026e-02 -0.17696970\nalt3_farm2    -4.025328e-02  0.035017796  -0.12030415  1.503802e-02 -0.21101995\nalt3_farm3    -9.876814e-03  0.019607843   0.02985407 -1.194163e-01  0.11024347\nalt3_height2   1.000000e+00 -0.503717523   0.03007604 -1.804562e-01 -0.05553157\nalt3_height3  -5.037175e-01  1.000000000  -0.01492704 -1.044893e-01  0.09554434\nalt3_redkite   3.007604e-02 -0.014927036   1.00000000  4.000000e-02  0.11570600\nalt3_distance -1.804562e-01 -0.104489251   0.04000000  1.000000e+00 -0.09354953\nalt3_cost     -5.553157e-02  0.095544337   0.11570600 -9.354953e-02  1.00000000\n\n\n\n\n\n\n# Print only the first three list elements\nlevel_balance(design)[1:3]\n\n$alt1_sq\n\n  1 \n100 \n\n$alt2_farm2\n\n 0  1 \n67 33 \n\n$alt2_farm3\n\n 0  1 \n66 34 \n\n\nFirst, we can see that the constant for the status quo alternative appears in all 100 rows of the design. Next, the medium and small wind farm sizes each occur 33 times, meaning the large size appears 34 times. This suggests the design is nearly balanced across attribute levels.\n\n\n\nDominant or dominated alternatives should be avoided because they don’t provide useful information about trade-offs and can bias your results.\nTo check for this, we can look at the choice probabilities for each alternative. If one option has a probability close to 1, it likely dominates the others. If it’s close to 0, it’s probably dominated.\nThe spdesign package includes a probabilities() function that calculates these values based on your design and priors. It shows the probability of choosing each alternative in every choice task. Each row of the output adds up to 1.\n\n# Check the utility balance by inspecting the probabilities. We use head() to avoid printing all 100 rows in the book.\nprobabilities(design) |&gt;\nhead()\n\n          alt1      alt2      alt3\n[1,] 0.3157344 0.2013212 0.4829444\n[2,] 0.2237765 0.3255929 0.4506306\n[3,] 0.2291680 0.4614876 0.3093444\n[4,] 0.1752196 0.5133922 0.3113881\n[5,] 0.2323560 0.2632939 0.5043501\n[6,] 0.2553926 0.2553926 0.4892149\n\n\nTo help spot any problematic choice tasks, we can create a simple plot. In this case, the plot shows no signs of dominating or dominated alternatives which would appear as very large or very small segments of a single color.\nThe status quo option (shown in red) has a low probability of being chosen, but it’s not too low to be a problem. What’s considered “too low” depends on the context. For example, in labelled experiments, some options are naturally chosen less often, especially if they represent less common situations.\nIf the status quo is chosen too often or too rarely compared to your expectations, you should adjust its prior value:\n\nIncrease the prior if you expect more people to choose the status quo.\nDecrease it if you expect fewer to choose it.\n\nThis step highlights why it’s important to check your design and make sure the priors match what you expect from real-world behavior.\n\n# Create a plot to show the choice shares across the design\nprobabilities(design) |&gt;\nas_tibble() |&gt;\nrowid_to_column() |&gt;\npivot_longer(-rowid, names_to = \"alt\", values_to = \"prob\") |&gt; ggplot(aes(x = rowid, y = prob, fill = alt)) + geom_bar(position = \"fill\", stat = \"identity\") +\nlabs(x = \"Choice task\", y = \"Choice probability\", fill = \"Alternative\") + scale_x_continuous(breaks = seq(1, 100, by = 2)) + scale_fill_discrete(label = c(\"SQ\", \"Alt 1\", \"Alt 2\")) +\ntheme_bw() +\ntheme(\nlegend.position = \"bottom\", axis.text.x = element_text(angle = 315)\n)\n\n\n\n\n\n\n\n\n\n\n\nSo next on the list would be check utility balance of each choice task in our design.\n\nutility_balance &lt;- function(x) {\n#Ensure that it is a matrix (and not a data.frame()/tibble()) \nx &lt;- as.matrix(x)\n\n# Find number of non-zero alternatives where 0 or NA can be non-available\nn_alts &lt;- apply(x, 1, function(y) sum(y &gt; 0, na.rm = TRUE)) \n\n# Calculate for each alternative\nx &lt;- x / (1 / n_alts)\n\n#Replace all zeroes with 1 to enable taking the product\nindex_zero &lt;- x == 0 \nx[index_zero] = 1\n\n# Take the product. This line requires the Rfast package.\nx &lt;- Rfast::rowprods(x) \nreturn(x)\n}\n\n# Use the function for utility balance on the choice probabilities\nutility_balance(probabilities(design)) |&gt; \nhead()\n\n[1] 0.8288430 0.8864901 0.8833240 0.7563066 0.8330874 0.8615488\n\n\nThe function returns the utility balance for each choice task. The average utility balance across the design is 0.8478. For efficient designs, values typically fall between 70% and 90% indicates a good balance, not too equal (which gives little information) and not too skewed to have dominant alternatives.\n\n\n\nThe design created in this includes 100 choice tasks which is far too many for a single respondent to handle effectively. To address this, we present two common solutions, starting with the most widely used: blocking.\nBlocking involves dividing the full design into smaller subsets, or blocks, so that each respondent is only shown the tasks from one block. For example, if pre-testing shows that respondents can comfortably complete 10 tasks, then a 100-task design would be split into 10 blocks of 10 tasks each.\nEach choice task still needs to be answered by at least one respondent, so blocking increases the number of participants required. In this case, you’d need at least 10 respondents (one per block), instead of just one respondent completing all 100 tasks. In general, larger designs with blocking demand more respondents to ensure all tasks are adequately covered.\nWhen using a blocked design, each respondent is randomly assigned to a block, and the order of choice tasks within that block is also randomized. Be sure to record the specific choice tasks shown to each respondent so you can accurately reconstruct their responses later.\nThe blocking column in your design must be orthogonal, meaning it should not be correlated with the other attributes. The block() function from the spdesign package creates a blocking column that minimizes mean squared correlation. However, it does not preserve attribute level balance within each block.\nIf your overall design is balanced, blocking won’t change that. But keep in mind that in a blocked design, some respondents may never see certain attribute levels, which could affect how realistic the choice tasks feel. Also, depending on the complexity of your design, generating the blocking column may take some time.\n\n# Add a blocking variable to the design with 10 blocks.\ndesign &lt;- block(design, 10)\n\nWarning in stats::cor(design, block): the standard deviation is zero\n\n\n\ndesign$blocks_correlation\n\n# A tibble: 1 × 15\n  alt1_sq alt2_farm2 alt2_farm3 alt2_height2 alt2_height3 alt2_redkite\n    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1      NA     0.0111    -0.0367       0.0259      0.00370       0.0419\n# ℹ 9 more variables: alt2_distance &lt;dbl&gt;, alt2_cost &lt;dbl&gt;, alt3_farm2 &lt;dbl&gt;,\n#   alt3_farm3 &lt;dbl&gt;, alt3_height2 &lt;dbl&gt;, alt3_height3 &lt;dbl&gt;,\n#   alt3_redkite &lt;dbl&gt;, alt3_distance &lt;dbl&gt;, alt3_cost &lt;dbl&gt;\n\n\nHere, we see that the blocking column is practically uncorrelated with the rest of the design."
  },
  {
    "objectID": "dce.html#attribute-levels",
    "href": "dce.html#attribute-levels",
    "title": "Discrete Choice Experiment",
    "section": "",
    "text": "Attributes\nLabels\nLevels\n\n\n\n\nSize of Wind Farm (discrete)\nSmall Farms\n0\n\n\nNote reference is LargeFarm\n\n1\n\n\n\nMediumFarms\n0\n\n\n\n\n1\n\n\nMax. Height Turbine (discrete)\nLow Height\n0\n\n\nNote reference is HighHeight\n\n1\n\n\n\nMedium Height\n0\n\n\n\n\n1\n\n\nReduction in Red Kite (continous)\nRed Kite\n5\n\n\n\n\n7.5\n\n\n\n\n10\n\n\n\n\n12.5\n\n\n\n\n15\n\n\nDistance to residents (continous)\nMinDistance\n750\n\n\n\n\n1000\n\n\n\n\n1250\n\n\n\n\n1500\n\n\n\n\n1750\n\n\nMonthlyCost\n(Continous)\nCost\n0\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n…..\n\n\n\n\n….\n\n\n\n\n10"
  },
  {
    "objectID": "dce.html#choice-set",
    "href": "dce.html#choice-set",
    "title": "Discrete Choice Experiment",
    "section": "",
    "text": "Lets first consider this example\n\nThis choice card has 3 alternatives and thus 3 different utility functions you are estimating:\n\nThe status quo or the opting out and keeping things the way they are. The utility function would look something like this:\n\n\\[\n\\begin{aligned}\nU_{n1t} =\\; & \\beta_{mf} \\, Med.Farms_{n1t} + \\beta_{sf} \\, SmallFarms_{n1t} \\\\& + \\beta_{mh} \\, Med.Height_{n1t} + \\beta_{lh}\n\\, LowHeight_{n1t} \\\\& + \\beta_{rk} \\, redKite_{n|t} + \\beta_{md} \\, MinDistance_{n1t} \\\\& + \\beta_{cost} \\, Cost_{n1t} + \\epsilon_{n1t}\n\\end{aligned}\n\\]\n\nProgram B will be alternative 2 and thus is indexed by 2\n\n\\[\n\\begin{aligned}\nU_{n2t}= \\beta_{mf}Med.Farms_{n2t}+\\beta_{sf}SmallFarms_{n2t} \\\\\n+\\beta_{mh}Med.Height_{n2t}+\\beta_{lh}LowHeight_{n2t} \\\\\n+\\beta_{rk}redKite_{n2t}+\\beta_{md}MinDistance_{n2t} \\\\\n\\beta_{cost}Cost_{n2t}+ \\epsilon_{n2t} \\\\\n\\end{aligned}\n\\]\n\nProgram C will be alternative 3 and thus is indexed by 3\n\\[\n\\begin{aligned}\nU_{n3t}= \\beta_{mf}Med.Farms_{n3t}+\\beta_{sf}SmallFarms_{n3t} \\\\\n+\\beta_{mh}Med.Height_{n3t}+\\beta_{lh}LowHeight_{n3t} \\\\\n+\\beta_{rk}redKite_{n3t}+\\beta_{md}MinDistance_{n3t} \\\\\n\\beta_{cost}Cost_{n3t}+ \\epsilon_{n3t} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "dce.html#experiential-design",
    "href": "dce.html#experiential-design",
    "title": "Discrete Choice Experiment",
    "section": "",
    "text": "We will now look at a full factorial design for the entire choice set and all the levels. Given the choices above the amount of possible combinations balloons to 5mil+ observations!\n\n# Create the full factorial using a named list of attributes and levels in the wide format\nfull_fact &lt;- full_factorial( list( alt1_sq = 1,\nalt1_farm = 0,\nalt1_height = 0,\nalt1_redkite = 0,\nalt1_distance = 0,\nalt1_cost = 0,\nalt2_sq = 0,\nalt2_farm = c(1, 2, 3),\nalt2_height = c(1, 2, 3),\nalt2_redkite = c(-5, -2.5, 0, 2.5, 5), alt2_distance = c(0, 0.25, 0.5, 0.75, 1), alt2_cost = 1:10,\nalt3_sq = 0,\nalt3_farm = c(1, 2, 3),\nalt3_height = c(1, 2, 3),\nalt3_redkite = c(-5, -2.5, 0, 2.5, 5), alt3_distance = c(0, 0.25, 0.5, 0.75, 1), alt3_cost = 1:10\n) )\n\n# Show the first six rows and 8th to 12th columns of the design matrix\nfull_fact[1:6, c(1, 8:12)]\n\n  alt1_sq alt2_farm alt2_height alt2_redkite alt2_distance alt2_cost\n1       1         1           1           -5             0         1\n2       1         2           1           -5             0         1\n3       1         3           1           -5             0         1\n4       1         1           2           -5             0         1\n5       1         2           2           -5             0         1\n6       1         3           2           -5             0         1\n\n\nAs the number of attributes, levels, and alternatives increases, full factorial designs become less practical for several reasons:\n\nDuplicate alternatives: Some choice tasks may repeat the same alternative, which doesn’t help us learn anything new about preferences.\nDominated alternatives: Some options in a choice task might be clearly worse (or better) than others in every way. These don’t help reveal trade-offs because people will always pick the best one, making the data less useful.\nLack of control: The full factorial includes all possible combinations, even unrealistic ones. For example, we might want to prevent small wind farms from showing up with the highest red kite impact.\n\n\n\nLets say we want to put restriction by putting logical restrictions. For example, the tall windmills cannot be placed too close to residential areas (this could already be a law and thus is a more accurate reflection of reality).\n\ncandidate_set &lt;- full_fact[!((full_fact$alt2_height == 1 & full_fact$alt2_distance &lt; 0.75) | (full_fact$alt3_height == 1 & full_fact$alt3_distance &lt; 0.75)), ]\n\ncandidate_set[1:6, c(1, 8:12)]\n\n     alt1_sq alt2_farm alt2_height alt2_redkite alt2_distance alt2_cost\n6754       1         1           2           -5             0         1\n6755       1         2           2           -5             0         1\n6756       1         3           2           -5             0         1\n6757       1         1           3           -5             0         1\n6758       1         2           3           -5             0         1\n6759       1         3           3           -5             0         1\n\n\nThis reduces the number of observations to 3.2million+ but does not make our choice set reasonable for population sampling. There for we move onto the next approach D-efficient\n\n\n\nIn statistics, we often try to reduce standard errors to improve the precision of our estimates. The same idea applies in Discrete Choice Experiments (DCEs). We want to design choice tasks that give us the most precise information.\nThink of it this way:\n\nWhen fitting a model, we already have the data and estimate the parameters that best explain it.\nWhen designing a DCE, we do the reverse: we assume values for the parameters (called priors) and then search for the combination of attributes and levels that will give us the most information — that is, the lowest standard errors or lowest D-error.\n\n\n\n\nFor our example we need to design a utility function to estimate the best set of potential choice cards. The utility function was written out within choice set section. So here we are going to use the library spdesign to write out each alternative.\n\nutility &lt;- list(\nalt1 = \"b_sq[0] * sq[1]\",\nalt2 = \"b_farm_dummy[c(0.25, 0.5)] * farm[c(1, 2, 3)] +\nb_height_dummy[c(0.25, 0.5)] * height[c(1, 2, 3)] + b_redkite[-0.05] * redkite[c(-5, -2.5, 0, 2.5, 5)] + b_distance[0.5] * distance[c(0, 0.25, 0.5, 0.75, 1)] + b_cost[-0.05] * cost[seq(1, 10)]\",\nalt3 = \"b_farm_dummy * farm + b_height_dummy * height +\nb_redkite * redkite + b_distance * distance + b_cost * cost\"\n)\n\n\n\n\nIn library spdesign generate_designis a function that generates efficient experimental designs. The function takes a set of indirect utility functions and generates efficient experimental designs assuming that people are maximizing utility.\nHere are the arguments needed for our example:\n\n\n\n\n\n\n\nutility\nA named list of utility functions. See the examples and the vignette for examples of how to define these correctly for different types of experimental designs.\n\n\nrows\nAn integer giving the number of rows in the final design\n\n\nmodel\nA character string indicating the model to optimize the design for. Currently the only model programmed is the ‘mnl’ model and this is also set as the default.\n\n\nefficiency_criteria\nA character string giving the efficiency criteria to optimize for. One of ‘a-error’, ‘c-error’, ‘d-error’ or ‘s-error’. No default is set and argument must be specified. Optimizing for multiple criteria is not yet implemented and will result in an error.\n\n\nalgorithm\nA character string giving the optimization algorithm to use. No default is set and the argument must be specified to be one of ‘rsc’, ‘federov’ or ‘random’.\n\n\n\n\n\n\n──────────────────────────────────────────────────────────────────────────────── \n Iteration   A-error   C-error   D-error   S-error               Time stamp\n──────────────────────────────────────────────────────────────────────────────── \n         1    0.1322       N/A    0.0423       Inf2025-09-20 21:19:06.380483\n──────────────────────────────────────────────────────────────────────────── \n\n\nTime spent searching for designs:  0.05410409 \n\n\n\nsummary(design)\n\n---------------------------------------------------------------------\nAn 'spdesign' object\n\nUtility functions:\nalt1 : b_sq * alt1_sq \nalt2 : b_farm_dummy * alt2_farm + b_height_dummy * alt2_height + b_redkite * alt2_redkite + b_distance * alt2_distance + b_cost * alt2_cost \nalt3 : b_farm_dummy * alt3_farm + b_height_dummy * alt3_height + b_redkite * alt3_redkite + b_distance * alt3_distance + b_cost * alt3_cost \n\n\n   a-error    c-error    d-error    s-error \n0.13218255        NaN 0.04234627        Inf \n\n---------------------------------------------------------------------\n\nPrinting the first few rows of the design \n# A tibble: 6 × 15\n  alt1_sq alt2_farm2 alt2_farm3 alt2_height2 alt2_height3 alt2_redkite\n    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1       1          0          0            0            0          0  \n2       1          0          0            1            0         -2.5\n3       1          0          0            1            0         -2.5\n4       1          1          0            0            1         -5  \n5       1          0          0            0            1          2.5\n6       1          1          0            0            0          2.5\n# ℹ 9 more variables: alt2_distance &lt;dbl&gt;, alt2_cost &lt;dbl&gt;, alt3_farm2 &lt;dbl&gt;,\n#   alt3_farm3 &lt;dbl&gt;, alt3_height2 &lt;dbl&gt;, alt3_height3 &lt;dbl&gt;,\n#   alt3_redkite &lt;dbl&gt;, alt3_distance &lt;dbl&gt;, alt3_cost &lt;dbl&gt;\n\n---------------------------------------------------------------------\n\n\n\n\n\nNext step check correlation\n\n# Correlation matrix\ncor(design)\n\nWarning in stats::cor(x[[\"design\"]], y = NULL, use = \"everything\", method =\nc(\"pearson\", : the standard deviation is zero\n\n\n              alt1_sq    alt2_farm2  alt2_farm3  alt2_height2 alt2_height3\nalt1_sq             1            NA          NA            NA           NA\nalt2_farm2         NA  1.000000e+00 -0.50371752 -4.025328e-02 -0.085481682\nalt2_farm3         NA -5.037175e-01  1.00000000 -5.477142e-02  0.124807016\nalt2_height2       NA -4.025328e-02 -0.05477142  1.000000e+00 -0.492537313\nalt2_height3       NA -8.548168e-02  0.12480702 -4.925373e-01  1.000000000\nalt2_redkite       NA  1.335644e-18 -0.10448925  9.022811e-02 -0.150380191\nalt2_distance      NA  3.007604e-02 -0.11941629 -9.022811e-02  0.060152076\nalt2_cost          NA -7.774419e-02  0.01469913  9.255261e-02 -0.166594697\nalt3_farm2         NA  1.406603e-01 -0.05477142  5.020353e-02  0.140660335\nalt3_farm3         NA -9.966603e-02  0.06417112 -9.876814e-03 -0.099666034\nalt3_height2       NA -8.548168e-02  0.12480702 -1.759385e-01  0.095431931\nalt3_height3       NA -1.894553e-01  0.15329768 -9.876814e-03 -0.009876814\nalt3_redkite       NA  7.519010e-02 -0.11941629  3.007604e-02 -0.015038019\nalt3_distance      NA -6.015208e-02  0.01492704  3.339111e-18 -0.105266133\nalt3_cost          NA -1.888073e-01  0.14699129 -1.851052e-02 -0.033318939\n               alt2_redkite alt2_distance   alt2_cost  alt3_farm2   alt3_farm3\nalt1_sq                  NA            NA          NA          NA           NA\nalt2_farm2     1.335644e-18  3.007604e-02 -0.07774419  0.14066033 -0.099666034\nalt2_farm3    -1.044893e-01 -1.194163e-01  0.01469913 -0.05477142  0.064171123\nalt2_height2   9.022811e-02 -9.022811e-02  0.09255261  0.05020353 -0.009876814\nalt2_height3  -1.503802e-01  6.015208e-02 -0.16659470  0.14066033 -0.099666034\nalt2_redkite   1.000000e+00 -4.500000e-02  0.10093502  0.04511406 -0.089562215\nalt2_distance -4.500000e-02  1.000000e+00  0.12062966 -0.12030415 -0.044781108\nalt2_cost      1.009350e-01  1.206297e-01  1.00000000  0.02591473 -0.132292159\nalt3_farm2     4.511406e-02 -1.203042e-01  0.02591473  1.00000000 -0.503717523\nalt3_farm3    -8.956222e-02 -4.478111e-02 -0.13229216 -0.50371752  1.000000000\nalt3_height2   4.511406e-02  1.836511e-17 -0.16659470 -0.04025328 -0.009876814\nalt3_height3  -8.956222e-02  8.956222e-02  0.09554434  0.03501780  0.019607843\nalt3_redkite   1.100000e-01  1.450000e-01 -0.05662209 -0.12030415  0.029854072\nalt3_distance  0.000000e+00  4.000000e-02  0.05416026  0.01503802 -0.119416287\nalt3_cost     -1.452480e-01 -6.154575e-02 -0.17696970 -0.21101995  0.110243466\n               alt3_height2 alt3_height3 alt3_redkite alt3_distance   alt3_cost\nalt1_sq                  NA           NA           NA            NA          NA\nalt2_farm2    -8.548168e-02 -0.189455254   0.07519010 -6.015208e-02 -0.18880732\nalt2_farm3     1.248070e-01  0.153297683  -0.11941629  1.492704e-02  0.14699129\nalt2_height2  -1.759385e-01 -0.009876814   0.03007604  3.339111e-18 -0.01851052\nalt2_height3   9.543193e-02 -0.009876814  -0.01503802 -1.052661e-01 -0.03331894\nalt2_redkite   4.511406e-02 -0.089562215   0.11000000  0.000000e+00 -0.14524796\nalt2_distance  1.836511e-17  0.089562215   0.14500000  4.000000e-02 -0.06154575\nalt2_cost     -1.665947e-01  0.095544337  -0.05662209  5.416026e-02 -0.17696970\nalt3_farm2    -4.025328e-02  0.035017796  -0.12030415  1.503802e-02 -0.21101995\nalt3_farm3    -9.876814e-03  0.019607843   0.02985407 -1.194163e-01  0.11024347\nalt3_height2   1.000000e+00 -0.503717523   0.03007604 -1.804562e-01 -0.05553157\nalt3_height3  -5.037175e-01  1.000000000  -0.01492704 -1.044893e-01  0.09554434\nalt3_redkite   3.007604e-02 -0.014927036   1.00000000  4.000000e-02  0.11570600\nalt3_distance -1.804562e-01 -0.104489251   0.04000000  1.000000e+00 -0.09354953\nalt3_cost     -5.553157e-02  0.095544337   0.11570600 -9.354953e-02  1.00000000\n\n\n\n\n\n\n# Print only the first three list elements\nlevel_balance(design)[1:3]\n\n$alt1_sq\n\n  1 \n100 \n\n$alt2_farm2\n\n 0  1 \n67 33 \n\n$alt2_farm3\n\n 0  1 \n66 34 \n\n\nFirst, we can see that the constant for the status quo alternative appears in all 100 rows of the design. Next, the medium and small wind farm sizes each occur 33 times, meaning the large size appears 34 times. This suggests the design is nearly balanced across attribute levels.\n\n\n\nDominant or dominated alternatives should be avoided because they don’t provide useful information about trade-offs and can bias your results.\nTo check for this, we can look at the choice probabilities for each alternative. If one option has a probability close to 1, it likely dominates the others. If it’s close to 0, it’s probably dominated.\nThe spdesign package includes a probabilities() function that calculates these values based on your design and priors. It shows the probability of choosing each alternative in every choice task. Each row of the output adds up to 1.\n\n# Check the utility balance by inspecting the probabilities. We use head() to avoid printing all 100 rows in the book.\nprobabilities(design) |&gt;\nhead()\n\n          alt1      alt2      alt3\n[1,] 0.3157344 0.2013212 0.4829444\n[2,] 0.2237765 0.3255929 0.4506306\n[3,] 0.2291680 0.4614876 0.3093444\n[4,] 0.1752196 0.5133922 0.3113881\n[5,] 0.2323560 0.2632939 0.5043501\n[6,] 0.2553926 0.2553926 0.4892149\n\n\nTo help spot any problematic choice tasks, we can create a simple plot. In this case, the plot shows no signs of dominating or dominated alternatives which would appear as very large or very small segments of a single color.\nThe status quo option (shown in red) has a low probability of being chosen, but it’s not too low to be a problem. What’s considered “too low” depends on the context. For example, in labelled experiments, some options are naturally chosen less often, especially if they represent less common situations.\nIf the status quo is chosen too often or too rarely compared to your expectations, you should adjust its prior value:\n\nIncrease the prior if you expect more people to choose the status quo.\nDecrease it if you expect fewer to choose it.\n\nThis step highlights why it’s important to check your design and make sure the priors match what you expect from real-world behavior.\n\n# Create a plot to show the choice shares across the design\nprobabilities(design) |&gt;\nas_tibble() |&gt;\nrowid_to_column() |&gt;\npivot_longer(-rowid, names_to = \"alt\", values_to = \"prob\") |&gt; ggplot(aes(x = rowid, y = prob, fill = alt)) + geom_bar(position = \"fill\", stat = \"identity\") +\nlabs(x = \"Choice task\", y = \"Choice probability\", fill = \"Alternative\") + scale_x_continuous(breaks = seq(1, 100, by = 2)) + scale_fill_discrete(label = c(\"SQ\", \"Alt 1\", \"Alt 2\")) +\ntheme_bw() +\ntheme(\nlegend.position = \"bottom\", axis.text.x = element_text(angle = 315)\n)\n\n\n\n\n\n\n\n\n\n\n\nSo next on the list would be check utility balance of each choice task in our design.\n\nutility_balance &lt;- function(x) {\n#Ensure that it is a matrix (and not a data.frame()/tibble()) \nx &lt;- as.matrix(x)\n\n# Find number of non-zero alternatives where 0 or NA can be non-available\nn_alts &lt;- apply(x, 1, function(y) sum(y &gt; 0, na.rm = TRUE)) \n\n# Calculate for each alternative\nx &lt;- x / (1 / n_alts)\n\n#Replace all zeroes with 1 to enable taking the product\nindex_zero &lt;- x == 0 \nx[index_zero] = 1\n\n# Take the product. This line requires the Rfast package.\nx &lt;- Rfast::rowprods(x) \nreturn(x)\n}\n\n# Use the function for utility balance on the choice probabilities\nutility_balance(probabilities(design)) |&gt; \nhead()\n\n[1] 0.8288430 0.8864901 0.8833240 0.7563066 0.8330874 0.8615488\n\n\nThe function returns the utility balance for each choice task. The average utility balance across the design is 0.8478. For efficient designs, values typically fall between 70% and 90% indicates a good balance, not too equal (which gives little information) and not too skewed to have dominant alternatives.\n\n\n\nThe design created in this includes 100 choice tasks which is far too many for a single respondent to handle effectively. To address this, we present two common solutions, starting with the most widely used: blocking.\nBlocking involves dividing the full design into smaller subsets, or blocks, so that each respondent is only shown the tasks from one block. For example, if pre-testing shows that respondents can comfortably complete 10 tasks, then a 100-task design would be split into 10 blocks of 10 tasks each.\nEach choice task still needs to be answered by at least one respondent, so blocking increases the number of participants required. In this case, you’d need at least 10 respondents (one per block), instead of just one respondent completing all 100 tasks. In general, larger designs with blocking demand more respondents to ensure all tasks are adequately covered.\nWhen using a blocked design, each respondent is randomly assigned to a block, and the order of choice tasks within that block is also randomized. Be sure to record the specific choice tasks shown to each respondent so you can accurately reconstruct their responses later.\nThe blocking column in your design must be orthogonal, meaning it should not be correlated with the other attributes. The block() function from the spdesign package creates a blocking column that minimizes mean squared correlation. However, it does not preserve attribute level balance within each block.\nIf your overall design is balanced, blocking won’t change that. But keep in mind that in a blocked design, some respondents may never see certain attribute levels, which could affect how realistic the choice tasks feel. Also, depending on the complexity of your design, generating the blocking column may take some time.\n\n# Add a blocking variable to the design with 10 blocks.\ndesign &lt;- block(design, 10)\n\nWarning in stats::cor(design, block): the standard deviation is zero\n\n\n\ndesign$blocks_correlation\n\n# A tibble: 1 × 15\n  alt1_sq alt2_farm2 alt2_farm3 alt2_height2 alt2_height3 alt2_redkite\n    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1      NA     0.0111    -0.0367       0.0259      0.00370       0.0419\n# ℹ 9 more variables: alt2_distance &lt;dbl&gt;, alt2_cost &lt;dbl&gt;, alt3_farm2 &lt;dbl&gt;,\n#   alt3_farm3 &lt;dbl&gt;, alt3_height2 &lt;dbl&gt;, alt3_height3 &lt;dbl&gt;,\n#   alt3_redkite &lt;dbl&gt;, alt3_distance &lt;dbl&gt;, alt3_cost &lt;dbl&gt;\n\n\nHere, we see that the blocking column is practically uncorrelated with the rest of the design."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Valuing Nature",
    "section": "",
    "text": "In this course, we begin each topic by reviewing the latest best practices for each method. While reading about how to estimate the value of nature is important, applying these methods in practice is half the battle. Throughout the course, we will periodically incorporate hands-on examples that demonstrate how to carry out these estimation techniques using real data.\nThis module is to help beginners with material on implementation of non-market valuation (NMV) with R (https://www.R-project.org). NMV methods have been widely applied in the social sciences such as environmental economics, agricultural economics, and transportation economics. Although various methods are associated with NMV, we focus on contingent valuation, discrete choice experiments, travel cost method, and hedonic pricing."
  },
  {
    "objectID": "index.html#what-is-r",
    "href": "index.html#what-is-r",
    "title": "Valuing Nature",
    "section": "What is R?",
    "text": "What is R?\nR is a programming language and software environment specifically designed for statistical computing and data analysis. It is widely used by statisticians, data scientists, researchers, and analysts to explore, model, and visualize data. Developed in the early 1990s, R has since become one of the most popular tools for applied statistics and quantitative analysis.\nR is open-source, meaning it’s free to use and supported by a large and active global community. Users can contribute packages to CRAN (the Comprehensive R Archive Network), which hosts thousands of libraries that extend R’s functionality across fields like economics, epidemiology, ecology, and more."
  },
  {
    "objectID": "index.html#download",
    "href": "index.html#download",
    "title": "Valuing Nature",
    "section": "Download",
    "text": "Download\nWe will be getting familiar with R (and RStudio, if necessary). If you are completely unfamiliar with R, you are advised to consult [An Introduction to R] (https://CRAN.R-project.org/manuals.html) or the other support material, which may be found on the websites mentioned below, before referring the contents.\n\nR Project (https://www.R-project.org/)\nThe Comprehensive R Archive Network (CRAN) (https://CRAN.R-project.org/)\nOfficial R Manuals on CRAN (https://CRAN.R-project.org/manuals.html)\nRStudio (https://www.RStudio.com/)"
  }
]